{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## <font color='Red'>MESSY-CLEAN ROOM CLASSIFIER WITH CNN ON AUGMENTED DATASET</font>","metadata":{}},{"cell_type":"markdown","source":"### For further information about the notebook and the details about each step, click at the following link https://github.com/Iron486/Clean_messy_room_classification and check the README.md file.","metadata":{}},{"cell_type":"markdown","source":"### Import libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom PIL import Image\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow.keras import layers\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\nimport statistics\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport time","metadata":{"execution":{"iopub.status.busy":"2022-06-09T13:39:44.402528Z","iopub.execute_input":"2022-06-09T13:39:44.402968Z","iopub.status.idle":"2022-06-09T13:39:50.951091Z","shell.execute_reply.started":"2022-06-09T13:39:44.402928Z","shell.execute_reply":"2022-06-09T13:39:50.950122Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### Train the model with a CNN with augmented dataset","metadata":{}},{"cell_type":"code","source":"size=180\nTRAINING_DIR = os.path.join('../input/messy-vs-clean-room/images','train')\ntrain_datagen = ImageDataGenerator(rescale=1/255,\n                                  rotation_range=3,\n                                  width_shift_range=0.1,\n                                  height_shift_range=0.1,\n                                  shear_range=0.1,\n                                  zoom_range=0.1,\n                                  horizontal_flip=True,\n                                  fill_mode='nearest')\n\n\ntrain_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n                                                   batch_size=40,\n                                                   class_mode='binary',\n                                                   target_size=(size,size))\n\nVALIDATION_DIR = os.path.join('../input/messy-vs-clean-room/images', 'val')\nvalidation_datagen = ImageDataGenerator(rescale=1/255)\n\n\nvalidation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n                                                             batch_size=40,\n                                                             class_mode='binary',\n                                                             target_size=(size,size))\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-09T13:40:02.858045Z","iopub.execute_input":"2022-06-09T13:40:02.858823Z","iopub.status.idle":"2022-06-09T13:40:03.086860Z","shell.execute_reply.started":"2022-06-09T13:40:02.858779Z","shell.execute_reply":"2022-06-09T13:40:03.084540Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"tf.random.set_seed(79)\n\n#model = tf.keras.applications.DenseNet169(include_top=True,weights=None,input_shape=(35,35,3),classes=1)\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(16, (3,3), activation='linear', input_shape=(size,size, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(32, (3,3)),#activation='linear'),\n    tf.keras.layers.Activation('linear'),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(64, (3,3), activation='linear'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(64, (3,3),  activation='linear'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(64, (3,3), activation='linear'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(1200, activation='linear'),\n    tf.keras.layers.Dropout(rate=0.15),\n    tf.keras.layers.Dense(38, activation='linear'),\n    tf.keras.layers.Dropout(rate=0.1),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n      ])\n\nopt = keras.optimizers.Adam(learning_rate=0.000004)\n\nearly_stopping_cb=keras.callbacks.EarlyStopping(patience=210,restore_best_weights=True)\nmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n\nmodel.summary()\n#pd.set_option('display.max_rows', 10)\n\nhistory = model.fit_generator(train_generator,\n                              epochs=7000,\n                              verbose=1,\n                              validation_data=validation_generator,callbacks=[early_stopping_cb])","metadata":{"execution":{"iopub.status.busy":"2022-06-09T13:40:06.066313Z","iopub.execute_input":"2022-06-09T13:40:06.066680Z","iopub.status.idle":"2022-06-09T15:34:31.037092Z","shell.execute_reply.started":"2022-06-09T13:40:06.066648Z","shell.execute_reply":"2022-06-09T15:34:31.036282Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(history.history).plot(figsize=(8, 5))\nplt.grid(True)\n#plt.gca().set_xlim(0,29)\nplt.gca().set_ylim(0,1)\n#model.save('my_keras_model_aug_180_slowlearn.h5')\nplt.savefig('/kaggle/working/CNN_dropout_augmented_dataset.png')\nloss, accuracy = model.evaluate(validation_generator)\n\n#print accuracy    \nprint('Accuracy: %f' % (accuracy*100))","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:37:22.618398Z","iopub.execute_input":"2022-06-09T15:37:22.619205Z","iopub.status.idle":"2022-06-09T15:37:23.170267Z","shell.execute_reply.started":"2022-06-09T15:37:22.619171Z","shell.execute_reply":"2022-06-09T15:37:23.169362Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### Details about the model","metadata":{}},{"cell_type":"code","source":"#model=keras.models.load_model('my_keras_model_aug_180_slowlearn.h5') \n\n#model.summary()\n\nfor i, layer in enumerate (model.layers):\n    print (i, layer)\n    try:\n        print (\"    \",layer.activation)\n    except AttributeError:\n        print('   no activation attribute')\n#specific info about each layer\nfor i in range(len(model.layers)):\n    print(model.layers[i].get_config())\n#info about optimizers\nmodel.optimizer.get_config()      ","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:37:57.132894Z","iopub.execute_input":"2022-06-09T15:37:57.133245Z","iopub.status.idle":"2022-06-09T15:37:57.148437Z","shell.execute_reply.started":"2022-06-09T15:37:57.133214Z","shell.execute_reply":"2022-06-09T15:37:57.147522Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### Show the entire validation dataset","metadata":{}},{"cell_type":"code","source":"images=[] \nn_classes=2\nfor i,filenames in enumerate(os.listdir(VALIDATION_DIR)): \n    dir_fold=os.path.join(VALIDATION_DIR, filenames)\n    class_images=[]\n    for filename in os.listdir(dir_fold):\n        img_path = os.path.join(dir_fold, filename)\n        class_images.append(mpimg.imread(img_path))\n    images.append(class_images)\n\n#valid for balanced classes\ncolumns = 5\nfig,axes=plt.subplots(int(len(images)*len(images[0])/columns),columns,figsize=(30,15))\nfor i,ind in enumerate(images):\n    fig.suptitle('Validation Dataset images',fontsize=47)\n    for j, image in enumerate(ind):\n        axes[int((i)*(len(ind)/columns)+(int(j/columns))),j % columns].imshow(image)","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:38:04.415134Z","iopub.execute_input":"2022-06-09T15:38:04.415534Z","iopub.status.idle":"2022-06-09T15:38:06.878668Z","shell.execute_reply.started":"2022-06-09T15:38:04.415497Z","shell.execute_reply":"2022-06-09T15:38:06.877759Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"len(images[0])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predict on test dataset","metadata":{}},{"cell_type":"code","source":"TEST_DIR = '../input/messy-vs-clean-room/images'\ntest_datagen = ImageDataGenerator(rescale=1/255)\ntest_generator = test_datagen.flow_from_directory(TEST_DIR,batch_size=40,\n                                                             classes=['test'],\n                                                              # don't generate labels\n                                                              class_mode=None,\n                                                              # don't shuffle\n                                                              shuffle=False,\n                                                             target_size=(size,size))","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:42:53.755156Z","iopub.execute_input":"2022-06-09T15:42:53.755534Z","iopub.status.idle":"2022-06-09T15:42:53.862575Z","shell.execute_reply.started":"2022-06-09T15:42:53.755493Z","shell.execute_reply":"2022-06-09T15:42:53.861745Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"files=test_generator.filenames\nfiles    ","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:38:45.845861Z","iopub.execute_input":"2022-06-09T15:38:45.846454Z","iopub.status.idle":"2022-06-09T15:38:45.853275Z","shell.execute_reply.started":"2022-06-09T15:38:45.846417Z","shell.execute_reply":"2022-06-09T15:38:45.852219Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#test_generator.reset()\npred=np.rint(model.predict(test_generator))\n#pred=np.argmax(pred, axis=-1)\npredicted_class_indices=np.array(pred).reshape(len(pred))\nlabels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npredictions = [labels[k] for k in predicted_class_indices]\nfilenames=test_generator.filenames\nresults=pd.DataFrame({\"Filename\":filenames,\n                      \"Predictions\":predictions})\nresults","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:55:16.450732Z","iopub.execute_input":"2022-06-09T15:55:16.451082Z","iopub.status.idle":"2022-06-09T15:55:16.605225Z","shell.execute_reply.started":"2022-06-09T15:55:16.451054Z","shell.execute_reply":"2022-06-09T15:55:16.604382Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"#### In this notebook, 90% accuracy on validation and 80% on test were reached. \n\n#### Training the model with my local GPU using the same model, 90% accuracy was reached for both test and validation datasets. Check out below:\n\n#### https://github.com/Iron486/Clean_messy_room_classification/blob/main/CNN_augmented_dataset_with_dropout.ipynb.","metadata":{}},{"cell_type":"code","source":"print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\ntf.config.list_physical_devices('GPU')","metadata":{"execution":{"iopub.status.busy":"2022-06-09T15:55:37.159640Z","iopub.execute_input":"2022-06-09T15:55:37.160244Z","iopub.status.idle":"2022-06-09T15:55:37.168095Z","shell.execute_reply.started":"2022-06-09T15:55:37.160208Z","shell.execute_reply":"2022-06-09T15:55:37.167346Z"},"trusted":true},"execution_count":42,"outputs":[]}]}