{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import statistics\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick and load one image from a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=80x80 at 0x20AE59978B0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im=Image.open(r\"C:\\\\Users\\diego\\OneDrive\\Desktop\\DS\\messy_nonmessy\\test\\0.png\",'r')\n",
    "im\n",
    "\n",
    "im= im.resize((80,80))\n",
    "im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the list of pixels in a single image\n",
    "example:\n",
    "\n",
    "[210,111,212] ---> [233] [111] [212]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pix_val = list(im.getdata())\n",
    "r_list=[]\n",
    "g_list=[]\n",
    "b_list=[]\n",
    "for x in pix_val:\n",
    "    for z in x:\n",
    "        if z==x[0]:\n",
    "            r_list.append(z)\n",
    "        elif z==x[1]:\n",
    "            g_list.append(z)\n",
    "        elif z==x[2]:\n",
    "            b_list.append(z)\n",
    "            \n",
    "#I've used a function of Image module called getdata() to extract the pixel values.\n",
    "#This scans the image horizontally from left to right starting at the top-left corner. \n",
    "#The values got from each pixel is then added into a list. \n",
    "#Finally what we get is a list with each pixel value as a set of 4 values(R,G,B.A)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick and load all the images from the directory and transform the list of pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_x=80 # size\n",
    "size_y=80 # size\n",
    "\n",
    "\n",
    "reshaped_images_clean_train= [] #np.zeros((size_x,size_y,3))\n",
    "reshaped_images_messy_train= []\n",
    "reshaped_images_clean_val= []\n",
    "reshaped_images_messy_val= []\n",
    "reshaped_images_test= []\n",
    "lists_xs_tot=[]\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    global size_x,size_y \n",
    "    for item in list_images:\n",
    "        img_iterative = os.path.join(folder,item)\n",
    "        for filename in os.listdir(img_iterative):    \n",
    "            img = os.path.join(img_iterative,filename)\n",
    "            if img is not None:      \n",
    "                im=Image.open(img,'r')\n",
    "                im=im.resize((size_x,size_y)) #size\n",
    "                pix_val=list(im.getdata())\n",
    "                #print(pix_val)\n",
    "                #print(np.array(pix_val).reshape((size_x,size_y,3)))\n",
    "                #print(np.array(pix_val).reshape((size_x,size_y,3)).shape)\n",
    "                r_list=[]\n",
    "                g_list=[]\n",
    "                b_list=[]  \n",
    "                lists_xs=[]\n",
    "                for x in pix_val:\n",
    "                    list_x=list(x)\n",
    "                    lists_xs.append(list_x)\n",
    "                    for z in x:\n",
    "                        if z==x[0]:\n",
    "                            r_list.append(z)\n",
    "                        elif z==x[1]:\n",
    "                            g_list.append(z)\n",
    "                        elif z==x[2]:\n",
    "                            b_list.append(z) \n",
    "                #np.array(lists_xs).reshape((size_x,size_y,3))            \n",
    "                #lists_xs_tot.append(lists_xs)\n",
    "                rgb_list=r_list+g_list+b_list \n",
    "                reshaped_image=np.array(rgb_list).reshape((size_x,size_y,3)).tolist()\n",
    "                rgb_list.insert(0,item)\n",
    "                images.append(rgb_list) \n",
    "                #used for CNNs\n",
    "                if item=='clean_train':\n",
    "                    reshaped_images_clean_train.append(reshaped_image)\n",
    "                elif item=='messy_train': \n",
    "                    reshaped_images_messy_train.append(reshaped_image)\n",
    "                elif item=='clean_val':\n",
    "                    reshaped_images_clean_val.append(reshaped_image)\n",
    "                elif  item=='messy_val':\n",
    "                    reshaped_images_messy_val.append(reshaped_image)\n",
    "                elif item =='test':\n",
    "                    reshaped_images_test.append(reshaped_image)\n",
    "                               \n",
    "                \n",
    "    return images\n",
    "folder=\"C:\\\\Users\\diego\\OneDrive\\Desktop\\DS\\messy_nonmessy\"\n",
    "\n",
    "list_images=['clean_train','clean_val','messy_train','messy_val','test']\n",
    "result=load_images_from_folder(folder)\n",
    "\n",
    "#print(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset=pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19191</th>\n",
       "      <th>19192</th>\n",
       "      <th>19193</th>\n",
       "      <th>19194</th>\n",
       "      <th>19195</th>\n",
       "      <th>19196</th>\n",
       "      <th>19197</th>\n",
       "      <th>19198</th>\n",
       "      <th>19199</th>\n",
       "      <th>19200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clean_train</td>\n",
       "      <td>128</td>\n",
       "      <td>114</td>\n",
       "      <td>108</td>\n",
       "      <td>103</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "      <td>97</td>\n",
       "      <td>114</td>\n",
       "      <td>114</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>31</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "      <td>34</td>\n",
       "      <td>42</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clean_train</td>\n",
       "      <td>178</td>\n",
       "      <td>177</td>\n",
       "      <td>178</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>181</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>...</td>\n",
       "      <td>86</td>\n",
       "      <td>96</td>\n",
       "      <td>81</td>\n",
       "      <td>64</td>\n",
       "      <td>117</td>\n",
       "      <td>132</td>\n",
       "      <td>122</td>\n",
       "      <td>110</td>\n",
       "      <td>111</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clean_train</td>\n",
       "      <td>216</td>\n",
       "      <td>218</td>\n",
       "      <td>224</td>\n",
       "      <td>225</td>\n",
       "      <td>213</td>\n",
       "      <td>188</td>\n",
       "      <td>181</td>\n",
       "      <td>210</td>\n",
       "      <td>229</td>\n",
       "      <td>...</td>\n",
       "      <td>95</td>\n",
       "      <td>98</td>\n",
       "      <td>96</td>\n",
       "      <td>94</td>\n",
       "      <td>84</td>\n",
       "      <td>78</td>\n",
       "      <td>86</td>\n",
       "      <td>82</td>\n",
       "      <td>86</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clean_train</td>\n",
       "      <td>218</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>213</td>\n",
       "      <td>211</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>210</td>\n",
       "      <td>...</td>\n",
       "      <td>54</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>58</td>\n",
       "      <td>52</td>\n",
       "      <td>54</td>\n",
       "      <td>55</td>\n",
       "      <td>50</td>\n",
       "      <td>53</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clean_train</td>\n",
       "      <td>150</td>\n",
       "      <td>155</td>\n",
       "      <td>158</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>163</td>\n",
       "      <td>163</td>\n",
       "      <td>166</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>test</td>\n",
       "      <td>210</td>\n",
       "      <td>211</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>213</td>\n",
       "      <td>213</td>\n",
       "      <td>213</td>\n",
       "      <td>213</td>\n",
       "      <td>214</td>\n",
       "      <td>...</td>\n",
       "      <td>131</td>\n",
       "      <td>140</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>154</td>\n",
       "      <td>84</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>123</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>test</td>\n",
       "      <td>191</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>185</td>\n",
       "      <td>186</td>\n",
       "      <td>186</td>\n",
       "      <td>...</td>\n",
       "      <td>199</td>\n",
       "      <td>210</td>\n",
       "      <td>215</td>\n",
       "      <td>217</td>\n",
       "      <td>218</td>\n",
       "      <td>240</td>\n",
       "      <td>248</td>\n",
       "      <td>250</td>\n",
       "      <td>252</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>test</td>\n",
       "      <td>120</td>\n",
       "      <td>94</td>\n",
       "      <td>91</td>\n",
       "      <td>83</td>\n",
       "      <td>147</td>\n",
       "      <td>147</td>\n",
       "      <td>99</td>\n",
       "      <td>103</td>\n",
       "      <td>105</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>29</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>test</td>\n",
       "      <td>173</td>\n",
       "      <td>171</td>\n",
       "      <td>168</td>\n",
       "      <td>163</td>\n",
       "      <td>160</td>\n",
       "      <td>156</td>\n",
       "      <td>152</td>\n",
       "      <td>148</td>\n",
       "      <td>148</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>29</td>\n",
       "      <td>35</td>\n",
       "      <td>28</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "      <td>29</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>test</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>46</td>\n",
       "      <td>52</td>\n",
       "      <td>54</td>\n",
       "      <td>59</td>\n",
       "      <td>57</td>\n",
       "      <td>58</td>\n",
       "      <td>64</td>\n",
       "      <td>66</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>222 rows × 19201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0      1      2      3      4      5      6      7      8      \\\n",
       "0    clean_train    128    114    108    103     95     93     97    114   \n",
       "1    clean_train    178    177    178    180    180    181    182    182   \n",
       "2    clean_train    216    218    224    225    213    188    181    210   \n",
       "3    clean_train    218    215    215    215    213    211    201    201   \n",
       "4    clean_train    150    155    158    161    161    161    163    163   \n",
       "..           ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "217         test    210    211    212    212    213    213    213    213   \n",
       "218         test    191    189    189    189    188    188    185    186   \n",
       "219         test    120     94     91     83    147    147     99    103   \n",
       "220         test    173    171    168    163    160    156    152    148   \n",
       "221         test    255    255    255    255    255    255    255    255   \n",
       "\n",
       "     9      ...  19191  19192  19193  19194  19195  19196  19197  19198  \\\n",
       "0      114  ...     40     31     27     26     28     30     34     42   \n",
       "1      182  ...     86     96     81     64    117    132    122    110   \n",
       "2      229  ...     95     98     96     94     84     78     86     82   \n",
       "3      210  ...     54     56     56     58     52     54     55     50   \n",
       "4      166  ...     12     10     10      9      8      7      7      7   \n",
       "..     ...  ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "217    214  ...    131    140    149    149    154     84     21     20   \n",
       "218    186  ...    199    210    215    217    218    240    248    250   \n",
       "219    105  ...      2      1      4     11     15     19     24     26   \n",
       "220    148  ...     26     32     33     29     35     28     25     21   \n",
       "221    255  ...     44     46     52     54     59     57     58     64   \n",
       "\n",
       "     19199  19200  \n",
       "0       40     40  \n",
       "1      111    124  \n",
       "2       86     87  \n",
       "3       53     55  \n",
       "4        7      6  \n",
       "..     ...    ...  \n",
       "217    123    157  \n",
       "218    252    254  \n",
       "219     29     35  \n",
       "220     29     33  \n",
       "221     66     67  \n",
       "\n",
       "[222 rows x 19201 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_pickle(r\"C:\\\\Users\\diego\\OneDrive\\Desktop\\DS\\messy_nonmessy\\raw_dataset_80pix.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        object\n",
       "1         int64\n",
       "2         int64\n",
       "3         int64\n",
       "4         int64\n",
       "          ...  \n",
       "19196     int64\n",
       "19197     int64\n",
       "19198     int64\n",
       "19199     int64\n",
       "19200     int64\n",
       "Length: 19201, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train=dataset[dataset[0]=='clean_train']\n",
    "clean_val=dataset[dataset[0]=='clean_val']\n",
    "messy_train=dataset[dataset[0]=='messy_train']\n",
    "messy_val=dataset[dataset[0]=='messy_val']\n",
    "test=dataset[dataset[0]=='test']\n",
    "train_dataset=pd.concat([clean_train,messy_train])\n",
    "val_dataset=pd.concat([clean_val,messy_val])\n",
    "test_dataset=pd.DataFrame(test)\n",
    "train_dataset.replace('clean_train','clean',inplace=True)\n",
    "train_dataset.replace('messy_train','messy',inplace=True)\n",
    "val_dataset.replace('clean_val','clean',inplace=True)\n",
    "val_dataset.replace('messy_val','messy',inplace=True)\n",
    "test_dataset.replace('clean_val','clean',inplace=True)\n",
    "test_dataset.replace('messy_val','messy',inplace=True)\n",
    "test_dataset.iloc[: , 0]=test_dataset.iloc[: , 0].astype(str)\n",
    "train_dataset.iloc[: , 0]=train_dataset.iloc[: , 0].astype(str)\n",
    "val_dataset.iloc[: , 0]=val_dataset.iloc[: , 0].astype(str)\n",
    "train_dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.to_pickle(r\"C:\\\\Users\\diego\\OneDrive\\Desktop\\DS\\messy_nonmessy\\train_dataset_raw_80pix.csv\")\n",
    "val_dataset.to_pickle(r\"C:\\\\Users\\diego\\OneDrive\\Desktop\\DS\\messy_nonmessy\\val_dataset_raw_80pix.csv\")\n",
    "test_dataset.to_pickle(r\"C:\\\\Users\\diego\\OneDrive\\Desktop\\DS\\messy_nonmessy\\test_dataset_raw_80pix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Variables</th>\n",
       "      <th>label</th>\n",
       "      <th colspan=\"9\" halign=\"left\">Red</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Blue</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>6391</th>\n",
       "      <th>6392</th>\n",
       "      <th>6393</th>\n",
       "      <th>6394</th>\n",
       "      <th>6395</th>\n",
       "      <th>6396</th>\n",
       "      <th>6397</th>\n",
       "      <th>6398</th>\n",
       "      <th>6399</th>\n",
       "      <th>6400</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clean</td>\n",
       "      <td>128</td>\n",
       "      <td>114</td>\n",
       "      <td>108</td>\n",
       "      <td>103</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "      <td>97</td>\n",
       "      <td>114</td>\n",
       "      <td>114</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>31</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "      <td>34</td>\n",
       "      <td>42</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clean</td>\n",
       "      <td>178</td>\n",
       "      <td>177</td>\n",
       "      <td>178</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>181</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>...</td>\n",
       "      <td>86</td>\n",
       "      <td>96</td>\n",
       "      <td>81</td>\n",
       "      <td>64</td>\n",
       "      <td>117</td>\n",
       "      <td>132</td>\n",
       "      <td>122</td>\n",
       "      <td>110</td>\n",
       "      <td>111</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clean</td>\n",
       "      <td>216</td>\n",
       "      <td>218</td>\n",
       "      <td>224</td>\n",
       "      <td>225</td>\n",
       "      <td>213</td>\n",
       "      <td>188</td>\n",
       "      <td>181</td>\n",
       "      <td>210</td>\n",
       "      <td>229</td>\n",
       "      <td>...</td>\n",
       "      <td>95</td>\n",
       "      <td>98</td>\n",
       "      <td>96</td>\n",
       "      <td>94</td>\n",
       "      <td>84</td>\n",
       "      <td>78</td>\n",
       "      <td>86</td>\n",
       "      <td>82</td>\n",
       "      <td>86</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clean</td>\n",
       "      <td>218</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>213</td>\n",
       "      <td>211</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>210</td>\n",
       "      <td>...</td>\n",
       "      <td>54</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>58</td>\n",
       "      <td>52</td>\n",
       "      <td>54</td>\n",
       "      <td>55</td>\n",
       "      <td>50</td>\n",
       "      <td>53</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clean</td>\n",
       "      <td>150</td>\n",
       "      <td>155</td>\n",
       "      <td>158</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>163</td>\n",
       "      <td>163</td>\n",
       "      <td>166</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>messy</td>\n",
       "      <td>171</td>\n",
       "      <td>166</td>\n",
       "      <td>168</td>\n",
       "      <td>171</td>\n",
       "      <td>172</td>\n",
       "      <td>175</td>\n",
       "      <td>174</td>\n",
       "      <td>172</td>\n",
       "      <td>168</td>\n",
       "      <td>...</td>\n",
       "      <td>110</td>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "      <td>108</td>\n",
       "      <td>106</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>101</td>\n",
       "      <td>94</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>messy</td>\n",
       "      <td>30</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>157</td>\n",
       "      <td>204</td>\n",
       "      <td>227</td>\n",
       "      <td>218</td>\n",
       "      <td>218</td>\n",
       "      <td>222</td>\n",
       "      <td>...</td>\n",
       "      <td>222</td>\n",
       "      <td>222</td>\n",
       "      <td>222</td>\n",
       "      <td>221</td>\n",
       "      <td>222</td>\n",
       "      <td>220</td>\n",
       "      <td>219</td>\n",
       "      <td>222</td>\n",
       "      <td>223</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>messy</td>\n",
       "      <td>214</td>\n",
       "      <td>230</td>\n",
       "      <td>189</td>\n",
       "      <td>150</td>\n",
       "      <td>154</td>\n",
       "      <td>156</td>\n",
       "      <td>158</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>...</td>\n",
       "      <td>177</td>\n",
       "      <td>159</td>\n",
       "      <td>151</td>\n",
       "      <td>92</td>\n",
       "      <td>95</td>\n",
       "      <td>103</td>\n",
       "      <td>93</td>\n",
       "      <td>95</td>\n",
       "      <td>63</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>messy</td>\n",
       "      <td>57</td>\n",
       "      <td>62</td>\n",
       "      <td>68</td>\n",
       "      <td>76</td>\n",
       "      <td>86</td>\n",
       "      <td>96</td>\n",
       "      <td>109</td>\n",
       "      <td>122</td>\n",
       "      <td>134</td>\n",
       "      <td>...</td>\n",
       "      <td>232</td>\n",
       "      <td>168</td>\n",
       "      <td>17</td>\n",
       "      <td>78</td>\n",
       "      <td>188</td>\n",
       "      <td>178</td>\n",
       "      <td>123</td>\n",
       "      <td>79</td>\n",
       "      <td>76</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>messy</td>\n",
       "      <td>94</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>27</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 19201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Variables  label  Red                                          ... Blue       \\\n",
       "Number      1    1    2    3    4    5    6    7    8    9     ... 6391 6392   \n",
       "0          clean  128  114  108  103   95   93   97  114  114  ...   40   31   \n",
       "1          clean  178  177  178  180  180  181  182  182  182  ...   86   96   \n",
       "2          clean  216  218  224  225  213  188  181  210  229  ...   95   98   \n",
       "3          clean  218  215  215  215  213  211  201  201  210  ...   54   56   \n",
       "4          clean  150  155  158  161  161  161  163  163  166  ...   12   10   \n",
       "..           ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "197        messy  171  166  168  171  172  175  174  172  168  ...  110  109   \n",
       "198        messy   30  107  107  157  204  227  218  218  222  ...  222  222   \n",
       "199        messy  214  230  189  150  154  156  158  159  159  ...  177  159   \n",
       "200        messy   57   62   68   76   86   96  109  122  134  ...  232  168   \n",
       "201        messy   94   62   62   27   20   21   20   21   20  ...    5    6   \n",
       "\n",
       "Variables                                          \n",
       "Number    6393 6394 6395 6396 6397 6398 6399 6400  \n",
       "0           27   26   28   30   34   42   40   40  \n",
       "1           81   64  117  132  122  110  111  124  \n",
       "2           96   94   84   78   86   82   86   87  \n",
       "3           56   58   52   54   55   50   53   55  \n",
       "4           10    9    8    7    7    7    7    6  \n",
       "..         ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "197        109  108  106  105  105  101   94   63  \n",
       "198        222  221  222  220  219  222  223  223  \n",
       "199        151   92   95  103   93   95   63   41  \n",
       "200         17   78  188  178  123   79   76  101  \n",
       "201          7    7    7   13    8    8   10   15  \n",
       "\n",
       "[192 rows x 19201 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size=(len(train_dataset.columns)-1)/3\n",
    "rgb=('Red','Green','Blue')\n",
    "columns=[]\n",
    "for colour in rgb:\n",
    "    for num in range(1,int(size+1)):\n",
    "        if colour=='Red'and num==1:\n",
    "            columns.append(('label', num))\n",
    "        columns.append((colour, num))\n",
    "train_dataset.columns = pd.MultiIndex.from_tuples(columns, names=['Variables','Number'])\n",
    "val_dataset.columns = pd.MultiIndex.from_tuples(columns, names=['Variables','Number'])\n",
    "test_dataset.columns = pd.MultiIndex.from_tuples(columns, names=['Variables','Number'])\n",
    "train_dataset['label']=train_dataset['label'].astype(str)\n",
    "train_dataset['Red']=train_dataset['Red'].astype('int')\n",
    "train_dataset['Blue']=train_dataset['Blue'].astype('int')\n",
    "train_dataset['Green']=train_dataset['Green'].astype('int')\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.to_pickle(r\"C:\\\\Users\\diego\\OneDrive\\Desktop\\DS\\messy_nonmessy\\train_dataset_80pix.csv\")\n",
    "val_dataset.to_pickle(r\"C:\\\\Users\\diego\\OneDrive\\Desktop\\DS\\messy_nonmessy\\val_dataset_80pix.csv\")\n",
    "test_dataset.to_pickle(r\"C:\\\\Users\\diego\\OneDrive\\Desktop\\DS\\messy_nonmessy\\test_dataset_80pix.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=pd.read_pickle(r\"C:\\\\Users\\diego\\OneDrive\\Desktop\\DS\\messy_nonmessy\\train_dataset_80pix.csv\")\n",
    "val_dataset=pd.read_pickle(r\"C:\\\\Users\\diego\\OneDrive\\Desktop\\DS\\messy_nonmessy\\val_dataset_80pix.csv\")\n",
    "test_dataset=pd.read_pickle(r\"C:\\\\Users\\diego\\OneDrive\\Desktop\\DS\\messy_nonmessy\\test_dataset_80pix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Variables</th>\n",
       "      <th>label</th>\n",
       "      <th colspan=\"9\" halign=\"left\">Red</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Blue</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>6391</th>\n",
       "      <th>6392</th>\n",
       "      <th>6393</th>\n",
       "      <th>6394</th>\n",
       "      <th>6395</th>\n",
       "      <th>6396</th>\n",
       "      <th>6397</th>\n",
       "      <th>6398</th>\n",
       "      <th>6399</th>\n",
       "      <th>6400</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clean</td>\n",
       "      <td>128</td>\n",
       "      <td>114</td>\n",
       "      <td>108</td>\n",
       "      <td>103</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "      <td>97</td>\n",
       "      <td>114</td>\n",
       "      <td>114</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>31</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "      <td>34</td>\n",
       "      <td>42</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clean</td>\n",
       "      <td>178</td>\n",
       "      <td>177</td>\n",
       "      <td>178</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>181</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>...</td>\n",
       "      <td>86</td>\n",
       "      <td>96</td>\n",
       "      <td>81</td>\n",
       "      <td>64</td>\n",
       "      <td>117</td>\n",
       "      <td>132</td>\n",
       "      <td>122</td>\n",
       "      <td>110</td>\n",
       "      <td>111</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clean</td>\n",
       "      <td>216</td>\n",
       "      <td>218</td>\n",
       "      <td>224</td>\n",
       "      <td>225</td>\n",
       "      <td>213</td>\n",
       "      <td>188</td>\n",
       "      <td>181</td>\n",
       "      <td>210</td>\n",
       "      <td>229</td>\n",
       "      <td>...</td>\n",
       "      <td>95</td>\n",
       "      <td>98</td>\n",
       "      <td>96</td>\n",
       "      <td>94</td>\n",
       "      <td>84</td>\n",
       "      <td>78</td>\n",
       "      <td>86</td>\n",
       "      <td>82</td>\n",
       "      <td>86</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clean</td>\n",
       "      <td>218</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>213</td>\n",
       "      <td>211</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>210</td>\n",
       "      <td>...</td>\n",
       "      <td>54</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>58</td>\n",
       "      <td>52</td>\n",
       "      <td>54</td>\n",
       "      <td>55</td>\n",
       "      <td>50</td>\n",
       "      <td>53</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clean</td>\n",
       "      <td>150</td>\n",
       "      <td>155</td>\n",
       "      <td>158</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>163</td>\n",
       "      <td>163</td>\n",
       "      <td>166</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>messy</td>\n",
       "      <td>171</td>\n",
       "      <td>166</td>\n",
       "      <td>168</td>\n",
       "      <td>171</td>\n",
       "      <td>172</td>\n",
       "      <td>175</td>\n",
       "      <td>174</td>\n",
       "      <td>172</td>\n",
       "      <td>168</td>\n",
       "      <td>...</td>\n",
       "      <td>110</td>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "      <td>108</td>\n",
       "      <td>106</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>101</td>\n",
       "      <td>94</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>messy</td>\n",
       "      <td>30</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>157</td>\n",
       "      <td>204</td>\n",
       "      <td>227</td>\n",
       "      <td>218</td>\n",
       "      <td>218</td>\n",
       "      <td>222</td>\n",
       "      <td>...</td>\n",
       "      <td>222</td>\n",
       "      <td>222</td>\n",
       "      <td>222</td>\n",
       "      <td>221</td>\n",
       "      <td>222</td>\n",
       "      <td>220</td>\n",
       "      <td>219</td>\n",
       "      <td>222</td>\n",
       "      <td>223</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>messy</td>\n",
       "      <td>214</td>\n",
       "      <td>230</td>\n",
       "      <td>189</td>\n",
       "      <td>150</td>\n",
       "      <td>154</td>\n",
       "      <td>156</td>\n",
       "      <td>158</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>...</td>\n",
       "      <td>177</td>\n",
       "      <td>159</td>\n",
       "      <td>151</td>\n",
       "      <td>92</td>\n",
       "      <td>95</td>\n",
       "      <td>103</td>\n",
       "      <td>93</td>\n",
       "      <td>95</td>\n",
       "      <td>63</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>messy</td>\n",
       "      <td>57</td>\n",
       "      <td>62</td>\n",
       "      <td>68</td>\n",
       "      <td>76</td>\n",
       "      <td>86</td>\n",
       "      <td>96</td>\n",
       "      <td>109</td>\n",
       "      <td>122</td>\n",
       "      <td>134</td>\n",
       "      <td>...</td>\n",
       "      <td>232</td>\n",
       "      <td>168</td>\n",
       "      <td>17</td>\n",
       "      <td>78</td>\n",
       "      <td>188</td>\n",
       "      <td>178</td>\n",
       "      <td>123</td>\n",
       "      <td>79</td>\n",
       "      <td>76</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>messy</td>\n",
       "      <td>94</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>27</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 19201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Variables  label  Red                                          ... Blue       \\\n",
       "Number      1    1    2    3    4    5    6    7    8    9     ... 6391 6392   \n",
       "0          clean  128  114  108  103   95   93   97  114  114  ...   40   31   \n",
       "1          clean  178  177  178  180  180  181  182  182  182  ...   86   96   \n",
       "2          clean  216  218  224  225  213  188  181  210  229  ...   95   98   \n",
       "3          clean  218  215  215  215  213  211  201  201  210  ...   54   56   \n",
       "4          clean  150  155  158  161  161  161  163  163  166  ...   12   10   \n",
       "..           ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "197        messy  171  166  168  171  172  175  174  172  168  ...  110  109   \n",
       "198        messy   30  107  107  157  204  227  218  218  222  ...  222  222   \n",
       "199        messy  214  230  189  150  154  156  158  159  159  ...  177  159   \n",
       "200        messy   57   62   68   76   86   96  109  122  134  ...  232  168   \n",
       "201        messy   94   62   62   27   20   21   20   21   20  ...    5    6   \n",
       "\n",
       "Variables                                          \n",
       "Number    6393 6394 6395 6396 6397 6398 6399 6400  \n",
       "0           27   26   28   30   34   42   40   40  \n",
       "1           81   64  117  132  122  110  111  124  \n",
       "2           96   94   84   78   86   82   86   87  \n",
       "3           56   58   52   54   55   50   53   55  \n",
       "4           10    9    8    7    7    7    7    6  \n",
       "..         ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "197        109  108  106  105  105  101   94   63  \n",
       "198        222  221  222  220  219  222  223  223  \n",
       "199        151   92   95  103   93   95   63   41  \n",
       "200         17   78  188  178  123   79   76  101  \n",
       "201          7    7    7   13    8    8   10   15  \n",
       "\n",
       "[192 rows x 19201 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset['label']=train_dataset['label'].replace('clean',1)#,inplace=True)\n",
    "train_dataset['label']=train_dataset['label'].replace('messy',0)#,inplace=True)\n",
    "train_dataset \n",
    "val_dataset['label']=val_dataset['label'].replace('clean',1)\n",
    "val_dataset['label']=val_dataset['label'].replace('messy',0)\n",
    "\n",
    "test_dataset['label']=test_dataset['label'].replace('clean',1)#,inplace=True)\n",
    "test_dataset['label']=test_dataset['label'].replace('messy',0)#,inplace=True)\n",
    "\n",
    "\n",
    "cat_encoder=OneHotEncoder()\n",
    "cat_features_1hot=cat_encoder.fit_transform(train_dataset['label'])#.to_array()\n",
    "\n",
    "\n",
    "scaler=StandardScaler()\n",
    "train_dataset_x=scaler.fit_transform(train_dataset.iloc[:,1:])\n",
    "val_dataset_x=scaler.fit_transform(val_dataset.iloc[:,1:])\n",
    "test_dataset_x=scaler.fit_transform(test_dataset.iloc[:,1:])\n",
    "\n",
    "#  another way to compute pca\n",
    "pca = PCA(n_components=0.99) \n",
    "train_dataset_pca = pca.fit_transform(train_dataset_x)\n",
    "input_shape=train_dataset_pca.shape[1]\n",
    "val_dataset_pca = pca.transform(val_dataset_x)\n",
    "#pca.singular_values_\n",
    "#train_dataset_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model and predict the test images with an ANN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 182)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 182)               728       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 182)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6000)              1098000   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              6001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                32032     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 7,135,793\n",
      "Trainable params: 7,133,429\n",
      "Non-trainable params: 2,364\n",
      "_________________________________________________________________\n",
      "Epoch 1/30900\n",
      "6/6 [==============================] - 1s 67ms/step - loss: 0.8250 - accuracy: 0.5729 - val_loss: 0.7220 - val_accuracy: 0.4500\n",
      "Epoch 2/30900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.9385 - accuracy: 0.4531 - val_loss: 0.7080 - val_accuracy: 0.4500\n",
      "Epoch 3/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.9077 - accuracy: 0.5104 - val_loss: 0.7019 - val_accuracy: 0.4500\n",
      "Epoch 4/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.9294 - accuracy: 0.4635 - val_loss: 0.6989 - val_accuracy: 0.4500\n",
      "Epoch 5/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.9793 - accuracy: 0.4427 - val_loss: 0.6967 - val_accuracy: 0.5000\n",
      "Epoch 6/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.9090 - accuracy: 0.5052 - val_loss: 0.6944 - val_accuracy: 0.5000\n",
      "Epoch 7/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.9999 - accuracy: 0.4479 - val_loss: 0.6926 - val_accuracy: 0.5000\n",
      "Epoch 8/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.9746 - accuracy: 0.4531 - val_loss: 0.6914 - val_accuracy: 0.5500\n",
      "Epoch 9/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.8904 - accuracy: 0.4844 - val_loss: 0.6907 - val_accuracy: 0.5500\n",
      "Epoch 10/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.8849 - accuracy: 0.5052 - val_loss: 0.6899 - val_accuracy: 0.5500\n",
      "Epoch 11/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.8633 - accuracy: 0.5521 - val_loss: 0.6886 - val_accuracy: 0.5500\n",
      "Epoch 12/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.9184 - accuracy: 0.5104 - val_loss: 0.6876 - val_accuracy: 0.5500\n",
      "Epoch 13/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.8431 - accuracy: 0.4896 - val_loss: 0.6871 - val_accuracy: 0.5500\n",
      "Epoch 14/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.8972 - accuracy: 0.5417 - val_loss: 0.6860 - val_accuracy: 0.5500\n",
      "Epoch 15/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.9011 - accuracy: 0.5260 - val_loss: 0.6850 - val_accuracy: 0.5500\n",
      "Epoch 16/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.8657 - accuracy: 0.4844 - val_loss: 0.6836 - val_accuracy: 0.5500\n",
      "Epoch 17/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.8968 - accuracy: 0.5104 - val_loss: 0.6826 - val_accuracy: 0.5500\n",
      "Epoch 18/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.7896 - accuracy: 0.5573 - val_loss: 0.6817 - val_accuracy: 0.5500\n",
      "Epoch 19/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.8473 - accuracy: 0.5365 - val_loss: 0.6807 - val_accuracy: 0.5500\n",
      "Epoch 20/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.8765 - accuracy: 0.5208 - val_loss: 0.6799 - val_accuracy: 0.5500\n",
      "Epoch 21/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.8732 - accuracy: 0.5312 - val_loss: 0.6789 - val_accuracy: 0.6000\n",
      "Epoch 22/30900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.8703 - accuracy: 0.5052 - val_loss: 0.6776 - val_accuracy: 0.6000\n",
      "Epoch 23/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.8274 - accuracy: 0.5365 - val_loss: 0.6765 - val_accuracy: 0.6000\n",
      "Epoch 24/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.8703 - accuracy: 0.5365 - val_loss: 0.6754 - val_accuracy: 0.6000\n",
      "Epoch 25/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.7817 - accuracy: 0.5521 - val_loss: 0.6744 - val_accuracy: 0.6000\n",
      "Epoch 26/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.7936 - accuracy: 0.5625 - val_loss: 0.6730 - val_accuracy: 0.6000\n",
      "Epoch 27/30900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.8223 - accuracy: 0.5208 - val_loss: 0.6718 - val_accuracy: 0.6000\n",
      "Epoch 28/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.8103 - accuracy: 0.5729 - val_loss: 0.6705 - val_accuracy: 0.6000\n",
      "Epoch 29/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.8355 - accuracy: 0.5208 - val_loss: 0.6693 - val_accuracy: 0.6000\n",
      "Epoch 30/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.8146 - accuracy: 0.5208 - val_loss: 0.6683 - val_accuracy: 0.6000\n",
      "Epoch 31/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.7884 - accuracy: 0.5469 - val_loss: 0.6670 - val_accuracy: 0.6000\n",
      "Epoch 32/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.7543 - accuracy: 0.5938 - val_loss: 0.6658 - val_accuracy: 0.6000\n",
      "Epoch 33/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.7783 - accuracy: 0.5833 - val_loss: 0.6649 - val_accuracy: 0.6000\n",
      "Epoch 34/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.7436 - accuracy: 0.5781 - val_loss: 0.6637 - val_accuracy: 0.6000\n",
      "Epoch 35/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.7527 - accuracy: 0.5833 - val_loss: 0.6625 - val_accuracy: 0.6500\n",
      "Epoch 36/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.7627 - accuracy: 0.5312 - val_loss: 0.6615 - val_accuracy: 0.6500\n",
      "Epoch 37/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.7410 - accuracy: 0.5573 - val_loss: 0.6607 - val_accuracy: 0.6500\n",
      "Epoch 38/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.7851 - accuracy: 0.5469 - val_loss: 0.6594 - val_accuracy: 0.6500\n",
      "Epoch 39/30900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.7782 - accuracy: 0.5677 - val_loss: 0.6584 - val_accuracy: 0.6500\n",
      "Epoch 40/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6891 - accuracy: 0.6615 - val_loss: 0.6576 - val_accuracy: 0.6500\n",
      "Epoch 41/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.7459 - accuracy: 0.5729 - val_loss: 0.6567 - val_accuracy: 0.6500\n",
      "Epoch 42/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.7019 - accuracy: 0.6146 - val_loss: 0.6564 - val_accuracy: 0.6500\n",
      "Epoch 43/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.7189 - accuracy: 0.6094 - val_loss: 0.6554 - val_accuracy: 0.6500\n",
      "Epoch 44/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6976 - accuracy: 0.6250 - val_loss: 0.6544 - val_accuracy: 0.6500\n",
      "Epoch 45/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.7662 - accuracy: 0.5469 - val_loss: 0.6535 - val_accuracy: 0.6500\n",
      "Epoch 46/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6510 - accuracy: 0.6510 - val_loss: 0.6519 - val_accuracy: 0.6500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6883 - accuracy: 0.5990 - val_loss: 0.6504 - val_accuracy: 0.6500\n",
      "Epoch 48/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.7233 - accuracy: 0.5885 - val_loss: 0.6489 - val_accuracy: 0.6500\n",
      "Epoch 49/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6921 - accuracy: 0.5990 - val_loss: 0.6474 - val_accuracy: 0.6500\n",
      "Epoch 50/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.7375 - accuracy: 0.5938 - val_loss: 0.6463 - val_accuracy: 0.6500\n",
      "Epoch 51/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.7249 - accuracy: 0.5833 - val_loss: 0.6449 - val_accuracy: 0.6500\n",
      "Epoch 52/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6771 - accuracy: 0.6719 - val_loss: 0.6436 - val_accuracy: 0.6500\n",
      "Epoch 53/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6898 - accuracy: 0.6146 - val_loss: 0.6423 - val_accuracy: 0.6500\n",
      "Epoch 54/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6871 - accuracy: 0.6250 - val_loss: 0.6411 - val_accuracy: 0.6500\n",
      "Epoch 55/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.7049 - accuracy: 0.6042 - val_loss: 0.6398 - val_accuracy: 0.6500\n",
      "Epoch 56/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6427 - accuracy: 0.6458 - val_loss: 0.6387 - val_accuracy: 0.6500\n",
      "Epoch 57/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6812 - accuracy: 0.6198 - val_loss: 0.6379 - val_accuracy: 0.6500\n",
      "Epoch 58/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6903 - accuracy: 0.6510 - val_loss: 0.6371 - val_accuracy: 0.6500\n",
      "Epoch 59/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6930 - accuracy: 0.6198 - val_loss: 0.6359 - val_accuracy: 0.6500\n",
      "Epoch 60/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6826 - accuracy: 0.5729 - val_loss: 0.6347 - val_accuracy: 0.6500\n",
      "Epoch 61/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6759 - accuracy: 0.6198 - val_loss: 0.6342 - val_accuracy: 0.6500\n",
      "Epoch 62/30900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6405 - accuracy: 0.6302 - val_loss: 0.6326 - val_accuracy: 0.6500\n",
      "Epoch 63/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6728 - accuracy: 0.6146 - val_loss: 0.6314 - val_accuracy: 0.6500\n",
      "Epoch 64/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6447 - accuracy: 0.6354 - val_loss: 0.6306 - val_accuracy: 0.6500\n",
      "Epoch 65/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6202 - accuracy: 0.6615 - val_loss: 0.6292 - val_accuracy: 0.6500\n",
      "Epoch 66/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6708 - accuracy: 0.6146 - val_loss: 0.6282 - val_accuracy: 0.6500\n",
      "Epoch 67/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6498 - accuracy: 0.6458 - val_loss: 0.6279 - val_accuracy: 0.7000\n",
      "Epoch 68/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.7111 - accuracy: 0.6146 - val_loss: 0.6275 - val_accuracy: 0.7000\n",
      "Epoch 69/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5936 - accuracy: 0.6979 - val_loss: 0.6266 - val_accuracy: 0.7000\n",
      "Epoch 70/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6282 - accuracy: 0.6823 - val_loss: 0.6255 - val_accuracy: 0.7000\n",
      "Epoch 71/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5886 - accuracy: 0.6719 - val_loss: 0.6247 - val_accuracy: 0.7000\n",
      "Epoch 72/30900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6372 - accuracy: 0.6302 - val_loss: 0.6245 - val_accuracy: 0.7000\n",
      "Epoch 73/30900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6730 - accuracy: 0.5833 - val_loss: 0.6235 - val_accuracy: 0.7000\n",
      "Epoch 74/30900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6346 - accuracy: 0.6927 - val_loss: 0.6228 - val_accuracy: 0.7000\n",
      "Epoch 75/30900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5915 - accuracy: 0.7083 - val_loss: 0.6224 - val_accuracy: 0.7000\n",
      "Epoch 76/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5998 - accuracy: 0.6979 - val_loss: 0.6208 - val_accuracy: 0.7000\n",
      "Epoch 77/30900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5616 - accuracy: 0.6979 - val_loss: 0.6200 - val_accuracy: 0.7000\n",
      "Epoch 78/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6697 - accuracy: 0.6094 - val_loss: 0.6187 - val_accuracy: 0.7000\n",
      "Epoch 79/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5879 - accuracy: 0.6875 - val_loss: 0.6175 - val_accuracy: 0.6500\n",
      "Epoch 80/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5810 - accuracy: 0.6979 - val_loss: 0.6169 - val_accuracy: 0.6500\n",
      "Epoch 81/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6157 - accuracy: 0.6562 - val_loss: 0.6157 - val_accuracy: 0.6500\n",
      "Epoch 82/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6049 - accuracy: 0.6979 - val_loss: 0.6141 - val_accuracy: 0.6500\n",
      "Epoch 83/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5570 - accuracy: 0.7344 - val_loss: 0.6134 - val_accuracy: 0.6500\n",
      "Epoch 84/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6082 - accuracy: 0.6510 - val_loss: 0.6124 - val_accuracy: 0.6500\n",
      "Epoch 85/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5816 - accuracy: 0.6927 - val_loss: 0.6113 - val_accuracy: 0.6500\n",
      "Epoch 86/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5705 - accuracy: 0.7083 - val_loss: 0.6105 - val_accuracy: 0.6500\n",
      "Epoch 87/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5556 - accuracy: 0.7240 - val_loss: 0.6095 - val_accuracy: 0.6500\n",
      "Epoch 88/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5748 - accuracy: 0.6979 - val_loss: 0.6086 - val_accuracy: 0.6500\n",
      "Epoch 89/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5053 - accuracy: 0.7708 - val_loss: 0.6079 - val_accuracy: 0.6500\n",
      "Epoch 90/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5653 - accuracy: 0.7344 - val_loss: 0.6076 - val_accuracy: 0.6500\n",
      "Epoch 91/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5849 - accuracy: 0.7344 - val_loss: 0.6072 - val_accuracy: 0.6500\n",
      "Epoch 92/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5707 - accuracy: 0.7135 - val_loss: 0.6062 - val_accuracy: 0.6500\n",
      "Epoch 93/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5489 - accuracy: 0.7448 - val_loss: 0.6055 - val_accuracy: 0.6500\n",
      "Epoch 94/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5483 - accuracy: 0.7240 - val_loss: 0.6050 - val_accuracy: 0.6500\n",
      "Epoch 95/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5716 - accuracy: 0.7031 - val_loss: 0.6047 - val_accuracy: 0.6500\n",
      "Epoch 96/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5252 - accuracy: 0.7292 - val_loss: 0.6039 - val_accuracy: 0.6500\n",
      "Epoch 97/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5193 - accuracy: 0.7396 - val_loss: 0.6031 - val_accuracy: 0.6500\n",
      "Epoch 98/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5179 - accuracy: 0.7448 - val_loss: 0.6027 - val_accuracy: 0.6500\n",
      "Epoch 99/30900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5440 - accuracy: 0.7448 - val_loss: 0.6024 - val_accuracy: 0.6500\n",
      "Epoch 100/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5386 - accuracy: 0.7448 - val_loss: 0.6018 - val_accuracy: 0.6500\n",
      "Epoch 101/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5309 - accuracy: 0.7500 - val_loss: 0.6011 - val_accuracy: 0.6500\n",
      "Epoch 102/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5587 - accuracy: 0.7083 - val_loss: 0.6006 - val_accuracy: 0.6500\n",
      "Epoch 103/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5511 - accuracy: 0.7292 - val_loss: 0.5993 - val_accuracy: 0.6500\n",
      "Epoch 104/30900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5091 - accuracy: 0.7552 - val_loss: 0.5983 - val_accuracy: 0.6500\n",
      "Epoch 105/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5513 - accuracy: 0.6927 - val_loss: 0.5976 - val_accuracy: 0.6500\n",
      "Epoch 106/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5268 - accuracy: 0.7188 - val_loss: 0.5970 - val_accuracy: 0.6500\n",
      "Epoch 107/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5282 - accuracy: 0.7135 - val_loss: 0.5959 - val_accuracy: 0.6500\n",
      "Epoch 108/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5158 - accuracy: 0.7604 - val_loss: 0.5954 - val_accuracy: 0.6500\n",
      "Epoch 109/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4881 - accuracy: 0.7344 - val_loss: 0.5956 - val_accuracy: 0.6500\n",
      "Epoch 110/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4839 - accuracy: 0.7969 - val_loss: 0.5957 - val_accuracy: 0.6500\n",
      "Epoch 111/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4986 - accuracy: 0.7656 - val_loss: 0.5946 - val_accuracy: 0.6500\n",
      "Epoch 112/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5019 - accuracy: 0.7448 - val_loss: 0.5932 - val_accuracy: 0.6000\n",
      "Epoch 113/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5020 - accuracy: 0.7917 - val_loss: 0.5924 - val_accuracy: 0.6000\n",
      "Epoch 114/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4611 - accuracy: 0.7917 - val_loss: 0.5912 - val_accuracy: 0.6000\n",
      "Epoch 115/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5036 - accuracy: 0.7292 - val_loss: 0.5902 - val_accuracy: 0.6000\n",
      "Epoch 116/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4895 - accuracy: 0.7917 - val_loss: 0.5898 - val_accuracy: 0.6000\n",
      "Epoch 117/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5017 - accuracy: 0.7656 - val_loss: 0.5896 - val_accuracy: 0.6000\n",
      "Epoch 118/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5125 - accuracy: 0.7604 - val_loss: 0.5888 - val_accuracy: 0.6000\n",
      "Epoch 119/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4786 - accuracy: 0.7917 - val_loss: 0.5884 - val_accuracy: 0.6000\n",
      "Epoch 120/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5080 - accuracy: 0.7552 - val_loss: 0.5877 - val_accuracy: 0.6000\n",
      "Epoch 121/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4824 - accuracy: 0.7708 - val_loss: 0.5867 - val_accuracy: 0.6000\n",
      "Epoch 122/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5097 - accuracy: 0.7448 - val_loss: 0.5860 - val_accuracy: 0.6000\n",
      "Epoch 123/30900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4974 - accuracy: 0.7500 - val_loss: 0.5852 - val_accuracy: 0.6000\n",
      "Epoch 124/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4868 - accuracy: 0.7656 - val_loss: 0.5840 - val_accuracy: 0.6000\n",
      "Epoch 125/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5192 - accuracy: 0.7344 - val_loss: 0.5829 - val_accuracy: 0.6000\n",
      "Epoch 126/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4862 - accuracy: 0.7917 - val_loss: 0.5820 - val_accuracy: 0.6000\n",
      "Epoch 127/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4628 - accuracy: 0.7760 - val_loss: 0.5812 - val_accuracy: 0.6000\n",
      "Epoch 128/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4403 - accuracy: 0.7969 - val_loss: 0.5807 - val_accuracy: 0.6000\n",
      "Epoch 129/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4402 - accuracy: 0.8385 - val_loss: 0.5805 - val_accuracy: 0.6000\n",
      "Epoch 130/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4305 - accuracy: 0.7969 - val_loss: 0.5802 - val_accuracy: 0.6000\n",
      "Epoch 131/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4953 - accuracy: 0.8021 - val_loss: 0.5799 - val_accuracy: 0.6000\n",
      "Epoch 132/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4668 - accuracy: 0.7969 - val_loss: 0.5795 - val_accuracy: 0.6000\n",
      "Epoch 133/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4868 - accuracy: 0.7708 - val_loss: 0.5786 - val_accuracy: 0.6000\n",
      "Epoch 134/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4895 - accuracy: 0.7969 - val_loss: 0.5777 - val_accuracy: 0.6000\n",
      "Epoch 135/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4956 - accuracy: 0.7812 - val_loss: 0.5772 - val_accuracy: 0.6000\n",
      "Epoch 136/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4377 - accuracy: 0.8177 - val_loss: 0.5765 - val_accuracy: 0.6000\n",
      "Epoch 137/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4501 - accuracy: 0.7396 - val_loss: 0.5764 - val_accuracy: 0.6000\n",
      "Epoch 138/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4328 - accuracy: 0.8073 - val_loss: 0.5754 - val_accuracy: 0.6000\n",
      "Epoch 139/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4392 - accuracy: 0.7708 - val_loss: 0.5750 - val_accuracy: 0.6000\n",
      "Epoch 140/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4292 - accuracy: 0.7917 - val_loss: 0.5750 - val_accuracy: 0.6000\n",
      "Epoch 141/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4298 - accuracy: 0.8073 - val_loss: 0.5747 - val_accuracy: 0.6000\n",
      "Epoch 142/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4344 - accuracy: 0.8229 - val_loss: 0.5742 - val_accuracy: 0.6000\n",
      "Epoch 143/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4772 - accuracy: 0.7969 - val_loss: 0.5739 - val_accuracy: 0.6000\n",
      "Epoch 144/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4381 - accuracy: 0.8021 - val_loss: 0.5733 - val_accuracy: 0.6000\n",
      "Epoch 145/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4182 - accuracy: 0.8333 - val_loss: 0.5729 - val_accuracy: 0.6000\n",
      "Epoch 146/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4326 - accuracy: 0.7969 - val_loss: 0.5722 - val_accuracy: 0.6000\n",
      "Epoch 147/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4441 - accuracy: 0.8125 - val_loss: 0.5719 - val_accuracy: 0.6000\n",
      "Epoch 148/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3971 - accuracy: 0.8542 - val_loss: 0.5710 - val_accuracy: 0.6000\n",
      "Epoch 149/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4489 - accuracy: 0.7604 - val_loss: 0.5705 - val_accuracy: 0.6000\n",
      "Epoch 150/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8438 - val_loss: 0.5696 - val_accuracy: 0.6500\n",
      "Epoch 151/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4017 - accuracy: 0.8385 - val_loss: 0.5690 - val_accuracy: 0.6500\n",
      "Epoch 152/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4318 - accuracy: 0.8177 - val_loss: 0.5686 - val_accuracy: 0.6500\n",
      "Epoch 153/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3944 - accuracy: 0.8177 - val_loss: 0.5686 - val_accuracy: 0.6500\n",
      "Epoch 154/30900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4279 - accuracy: 0.7969 - val_loss: 0.5686 - val_accuracy: 0.6500\n",
      "Epoch 155/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3954 - accuracy: 0.8385 - val_loss: 0.5680 - val_accuracy: 0.6500\n",
      "Epoch 156/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4209 - accuracy: 0.8385 - val_loss: 0.5679 - val_accuracy: 0.6500\n",
      "Epoch 157/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4356 - accuracy: 0.8021 - val_loss: 0.5676 - val_accuracy: 0.6500\n",
      "Epoch 158/30900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3508 - accuracy: 0.8438 - val_loss: 0.5669 - val_accuracy: 0.6500\n",
      "Epoch 159/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4183 - accuracy: 0.8229 - val_loss: 0.5669 - val_accuracy: 0.6500\n",
      "Epoch 160/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4406 - accuracy: 0.7969 - val_loss: 0.5669 - val_accuracy: 0.6500\n",
      "Epoch 161/30900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3841 - accuracy: 0.8594 - val_loss: 0.5663 - val_accuracy: 0.6500\n",
      "Epoch 162/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4293 - accuracy: 0.7865 - val_loss: 0.5661 - val_accuracy: 0.6500\n",
      "Epoch 163/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3736 - accuracy: 0.8750 - val_loss: 0.5658 - val_accuracy: 0.6500\n",
      "Epoch 164/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3756 - accuracy: 0.8594 - val_loss: 0.5654 - val_accuracy: 0.6500\n",
      "Epoch 165/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3904 - accuracy: 0.8438 - val_loss: 0.5653 - val_accuracy: 0.6500\n",
      "Epoch 166/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3815 - accuracy: 0.8281 - val_loss: 0.5644 - val_accuracy: 0.6500\n",
      "Epoch 167/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3867 - accuracy: 0.8438 - val_loss: 0.5637 - val_accuracy: 0.6500\n",
      "Epoch 168/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4172 - accuracy: 0.8438 - val_loss: 0.5634 - val_accuracy: 0.6500\n",
      "Epoch 169/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3635 - accuracy: 0.8802 - val_loss: 0.5632 - val_accuracy: 0.6500\n",
      "Epoch 170/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3577 - accuracy: 0.8698 - val_loss: 0.5624 - val_accuracy: 0.6500\n",
      "Epoch 171/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3659 - accuracy: 0.8438 - val_loss: 0.5623 - val_accuracy: 0.6500\n",
      "Epoch 172/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3720 - accuracy: 0.8594 - val_loss: 0.5619 - val_accuracy: 0.6500\n",
      "Epoch 173/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3796 - accuracy: 0.8594 - val_loss: 0.5610 - val_accuracy: 0.6500\n",
      "Epoch 174/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4111 - accuracy: 0.8333 - val_loss: 0.5607 - val_accuracy: 0.6500\n",
      "Epoch 175/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3768 - accuracy: 0.8542 - val_loss: 0.5606 - val_accuracy: 0.6500\n",
      "Epoch 176/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3549 - accuracy: 0.8802 - val_loss: 0.5599 - val_accuracy: 0.6500\n",
      "Epoch 177/30900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3621 - accuracy: 0.8594 - val_loss: 0.5597 - val_accuracy: 0.6500\n",
      "Epoch 178/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3390 - accuracy: 0.8958 - val_loss: 0.5592 - val_accuracy: 0.6500\n",
      "Epoch 179/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3897 - accuracy: 0.8646 - val_loss: 0.5587 - val_accuracy: 0.6500\n",
      "Epoch 180/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3714 - accuracy: 0.8594 - val_loss: 0.5586 - val_accuracy: 0.6500\n",
      "Epoch 181/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3333 - accuracy: 0.8906 - val_loss: 0.5582 - val_accuracy: 0.6500\n",
      "Epoch 182/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3725 - accuracy: 0.8594 - val_loss: 0.5584 - val_accuracy: 0.6500\n",
      "Epoch 183/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3641 - accuracy: 0.8542 - val_loss: 0.5581 - val_accuracy: 0.6500\n",
      "Epoch 184/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3735 - accuracy: 0.8438 - val_loss: 0.5576 - val_accuracy: 0.6500\n",
      "Epoch 185/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3362 - accuracy: 0.8958 - val_loss: 0.5569 - val_accuracy: 0.6500\n",
      "Epoch 186/30900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3926 - accuracy: 0.8698 - val_loss: 0.5570 - val_accuracy: 0.6500\n",
      "Epoch 187/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3618 - accuracy: 0.8385 - val_loss: 0.5571 - val_accuracy: 0.6500\n",
      "Epoch 188/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3520 - accuracy: 0.8698 - val_loss: 0.5563 - val_accuracy: 0.6500\n",
      "Epoch 189/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3757 - accuracy: 0.8542 - val_loss: 0.5558 - val_accuracy: 0.6500\n",
      "Epoch 190/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3502 - accuracy: 0.9062 - val_loss: 0.5554 - val_accuracy: 0.6500\n",
      "Epoch 191/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3805 - accuracy: 0.8542 - val_loss: 0.5551 - val_accuracy: 0.6500\n",
      "Epoch 192/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3397 - accuracy: 0.8958 - val_loss: 0.5558 - val_accuracy: 0.6500\n",
      "Epoch 193/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3664 - accuracy: 0.8802 - val_loss: 0.5562 - val_accuracy: 0.6500\n",
      "Epoch 194/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3730 - accuracy: 0.8281 - val_loss: 0.5558 - val_accuracy: 0.6500\n",
      "Epoch 195/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3557 - accuracy: 0.8542 - val_loss: 0.5555 - val_accuracy: 0.6500\n",
      "Epoch 196/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3329 - accuracy: 0.8802 - val_loss: 0.5551 - val_accuracy: 0.6500\n",
      "Epoch 197/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3527 - accuracy: 0.8854 - val_loss: 0.5550 - val_accuracy: 0.6500\n",
      "Epoch 198/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3143 - accuracy: 0.8958 - val_loss: 0.5547 - val_accuracy: 0.6500\n",
      "Epoch 199/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3638 - accuracy: 0.8594 - val_loss: 0.5540 - val_accuracy: 0.6500\n",
      "Epoch 200/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3414 - accuracy: 0.8906 - val_loss: 0.5536 - val_accuracy: 0.6500\n",
      "Epoch 201/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3463 - accuracy: 0.8750 - val_loss: 0.5531 - val_accuracy: 0.6500\n",
      "Epoch 202/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3398 - accuracy: 0.9010 - val_loss: 0.5524 - val_accuracy: 0.6500\n",
      "Epoch 203/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3666 - accuracy: 0.8594 - val_loss: 0.5521 - val_accuracy: 0.6500\n",
      "Epoch 204/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3031 - accuracy: 0.9062 - val_loss: 0.5517 - val_accuracy: 0.6500\n",
      "Epoch 205/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3397 - accuracy: 0.8542 - val_loss: 0.5517 - val_accuracy: 0.6500\n",
      "Epoch 206/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3229 - accuracy: 0.9115 - val_loss: 0.5517 - val_accuracy: 0.6500\n",
      "Epoch 207/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3033 - accuracy: 0.9062 - val_loss: 0.5513 - val_accuracy: 0.6500\n",
      "Epoch 208/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3234 - accuracy: 0.8958 - val_loss: 0.5509 - val_accuracy: 0.6500\n",
      "Epoch 209/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3442 - accuracy: 0.8594 - val_loss: 0.5504 - val_accuracy: 0.6500\n",
      "Epoch 210/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3333 - accuracy: 0.8802 - val_loss: 0.5502 - val_accuracy: 0.6500\n",
      "Epoch 211/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3372 - accuracy: 0.9010 - val_loss: 0.5502 - val_accuracy: 0.6500\n",
      "Epoch 212/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3184 - accuracy: 0.8854 - val_loss: 0.5497 - val_accuracy: 0.6500\n",
      "Epoch 213/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3030 - accuracy: 0.9010 - val_loss: 0.5490 - val_accuracy: 0.6500\n",
      "Epoch 214/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3428 - accuracy: 0.8594 - val_loss: 0.5495 - val_accuracy: 0.6500\n",
      "Epoch 215/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3467 - accuracy: 0.8542 - val_loss: 0.5493 - val_accuracy: 0.6500\n",
      "Epoch 216/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3564 - accuracy: 0.8542 - val_loss: 0.5495 - val_accuracy: 0.6500\n",
      "Epoch 217/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3261 - accuracy: 0.9010 - val_loss: 0.5492 - val_accuracy: 0.6500\n",
      "Epoch 218/30900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3042 - accuracy: 0.8854 - val_loss: 0.5492 - val_accuracy: 0.6500\n",
      "Epoch 219/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3209 - accuracy: 0.9062 - val_loss: 0.5493 - val_accuracy: 0.6500\n",
      "Epoch 220/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3377 - accuracy: 0.8802 - val_loss: 0.5496 - val_accuracy: 0.6500\n",
      "Epoch 221/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3306 - accuracy: 0.9115 - val_loss: 0.5495 - val_accuracy: 0.6500\n",
      "Epoch 222/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3016 - accuracy: 0.9219 - val_loss: 0.5495 - val_accuracy: 0.6500\n",
      "Epoch 223/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3367 - accuracy: 0.8698 - val_loss: 0.5494 - val_accuracy: 0.6500\n",
      "Epoch 224/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3053 - accuracy: 0.9010 - val_loss: 0.5491 - val_accuracy: 0.6500\n",
      "Epoch 225/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3210 - accuracy: 0.9010 - val_loss: 0.5489 - val_accuracy: 0.6500\n",
      "Epoch 226/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3016 - accuracy: 0.9219 - val_loss: 0.5481 - val_accuracy: 0.6500\n",
      "Epoch 227/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3375 - accuracy: 0.8698 - val_loss: 0.5478 - val_accuracy: 0.6500\n",
      "Epoch 228/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2984 - accuracy: 0.9271 - val_loss: 0.5479 - val_accuracy: 0.6500\n",
      "Epoch 229/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3019 - accuracy: 0.9323 - val_loss: 0.5480 - val_accuracy: 0.6500\n",
      "Epoch 230/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3147 - accuracy: 0.8854 - val_loss: 0.5477 - val_accuracy: 0.6500\n",
      "Epoch 231/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3201 - accuracy: 0.8906 - val_loss: 0.5474 - val_accuracy: 0.6500\n",
      "Epoch 232/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2963 - accuracy: 0.9062 - val_loss: 0.5473 - val_accuracy: 0.6500\n",
      "Epoch 233/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3060 - accuracy: 0.8646 - val_loss: 0.5473 - val_accuracy: 0.6500\n",
      "Epoch 234/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2927 - accuracy: 0.9323 - val_loss: 0.5472 - val_accuracy: 0.6500\n",
      "Epoch 235/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2636 - accuracy: 0.9375 - val_loss: 0.5472 - val_accuracy: 0.6500\n",
      "Epoch 236/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3170 - accuracy: 0.8906 - val_loss: 0.5474 - val_accuracy: 0.6500\n",
      "Epoch 237/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2955 - accuracy: 0.9219 - val_loss: 0.5472 - val_accuracy: 0.6500\n",
      "Epoch 238/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2972 - accuracy: 0.9010 - val_loss: 0.5474 - val_accuracy: 0.6500\n",
      "Epoch 239/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3100 - accuracy: 0.9167 - val_loss: 0.5472 - val_accuracy: 0.6500\n",
      "Epoch 240/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3274 - accuracy: 0.8906 - val_loss: 0.5469 - val_accuracy: 0.6500\n",
      "Epoch 241/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2709 - accuracy: 0.9427 - val_loss: 0.5470 - val_accuracy: 0.6500\n",
      "Epoch 242/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3117 - accuracy: 0.9115 - val_loss: 0.5467 - val_accuracy: 0.6500\n",
      "Epoch 243/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2945 - accuracy: 0.9062 - val_loss: 0.5470 - val_accuracy: 0.6500\n",
      "Epoch 244/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3078 - accuracy: 0.9010 - val_loss: 0.5473 - val_accuracy: 0.6500\n",
      "Epoch 245/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3459 - accuracy: 0.8750 - val_loss: 0.5475 - val_accuracy: 0.7000\n",
      "Epoch 246/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2796 - accuracy: 0.9062 - val_loss: 0.5476 - val_accuracy: 0.7000\n",
      "Epoch 247/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2569 - accuracy: 0.9479 - val_loss: 0.5477 - val_accuracy: 0.7000\n",
      "Epoch 248/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2752 - accuracy: 0.9323 - val_loss: 0.5479 - val_accuracy: 0.7000\n",
      "Epoch 249/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2942 - accuracy: 0.9010 - val_loss: 0.5484 - val_accuracy: 0.7000\n",
      "Epoch 250/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3083 - accuracy: 0.9010 - val_loss: 0.5490 - val_accuracy: 0.7000\n",
      "Epoch 251/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2556 - accuracy: 0.9635 - val_loss: 0.5488 - val_accuracy: 0.7000\n",
      "Epoch 252/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2483 - accuracy: 0.9427 - val_loss: 0.5491 - val_accuracy: 0.7000\n",
      "Epoch 253/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2724 - accuracy: 0.9115 - val_loss: 0.5489 - val_accuracy: 0.7000\n",
      "Epoch 254/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2872 - accuracy: 0.8958 - val_loss: 0.5494 - val_accuracy: 0.7000\n",
      "Epoch 255/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2732 - accuracy: 0.9010 - val_loss: 0.5492 - val_accuracy: 0.7000\n",
      "Epoch 256/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3099 - accuracy: 0.9167 - val_loss: 0.5495 - val_accuracy: 0.7000\n",
      "Epoch 257/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2399 - accuracy: 0.9375 - val_loss: 0.5494 - val_accuracy: 0.7000\n",
      "Epoch 258/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2778 - accuracy: 0.9375 - val_loss: 0.5491 - val_accuracy: 0.7000\n",
      "Epoch 259/30900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.2693 - accuracy: 0.9115 - val_loss: 0.5490 - val_accuracy: 0.7000\n",
      "Epoch 260/30900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.2501 - accuracy: 0.9323 - val_loss: 0.5491 - val_accuracy: 0.7000\n",
      "Epoch 261/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2857 - accuracy: 0.8958 - val_loss: 0.5491 - val_accuracy: 0.7000\n",
      "Epoch 262/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2743 - accuracy: 0.9271 - val_loss: 0.5493 - val_accuracy: 0.7000\n",
      "Epoch 263/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2924 - accuracy: 0.9375 - val_loss: 0.5496 - val_accuracy: 0.7000\n",
      "Epoch 264/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2768 - accuracy: 0.9219 - val_loss: 0.5494 - val_accuracy: 0.7000\n",
      "Epoch 265/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2838 - accuracy: 0.8958 - val_loss: 0.5493 - val_accuracy: 0.7000\n",
      "Epoch 266/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2726 - accuracy: 0.9219 - val_loss: 0.5486 - val_accuracy: 0.7000\n",
      "Epoch 267/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2520 - accuracy: 0.9323 - val_loss: 0.5484 - val_accuracy: 0.7000\n",
      "Epoch 268/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2818 - accuracy: 0.9219 - val_loss: 0.5485 - val_accuracy: 0.7000\n",
      "Epoch 269/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2551 - accuracy: 0.9167 - val_loss: 0.5486 - val_accuracy: 0.7000\n",
      "Epoch 270/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2943 - accuracy: 0.9167 - val_loss: 0.5488 - val_accuracy: 0.7000\n",
      "Epoch 271/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2757 - accuracy: 0.9062 - val_loss: 0.5486 - val_accuracy: 0.7000\n",
      "Epoch 272/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2659 - accuracy: 0.9271 - val_loss: 0.5488 - val_accuracy: 0.7000\n",
      "Epoch 273/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2252 - accuracy: 0.9531 - val_loss: 0.5491 - val_accuracy: 0.7000\n",
      "Epoch 274/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2682 - accuracy: 0.9115 - val_loss: 0.5494 - val_accuracy: 0.7000\n",
      "Epoch 275/30900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2530 - accuracy: 0.9219 - val_loss: 0.5497 - val_accuracy: 0.7000\n",
      "Epoch 276/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2728 - accuracy: 0.9323 - val_loss: 0.5498 - val_accuracy: 0.7000\n",
      "Epoch 277/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2463 - accuracy: 0.9323 - val_loss: 0.5498 - val_accuracy: 0.7000\n",
      "Epoch 278/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2455 - accuracy: 0.9479 - val_loss: 0.5496 - val_accuracy: 0.7000\n",
      "Epoch 279/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2776 - accuracy: 0.9010 - val_loss: 0.5495 - val_accuracy: 0.7000\n",
      "Epoch 280/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2714 - accuracy: 0.9062 - val_loss: 0.5500 - val_accuracy: 0.7000\n",
      "Epoch 281/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2977 - accuracy: 0.9062 - val_loss: 0.5503 - val_accuracy: 0.7000\n",
      "Epoch 282/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2429 - accuracy: 0.9479 - val_loss: 0.5501 - val_accuracy: 0.7000\n",
      "Epoch 283/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2406 - accuracy: 0.9375 - val_loss: 0.5497 - val_accuracy: 0.7000\n",
      "Epoch 284/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2535 - accuracy: 0.9427 - val_loss: 0.5499 - val_accuracy: 0.7000\n",
      "Epoch 285/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2655 - accuracy: 0.9167 - val_loss: 0.5500 - val_accuracy: 0.7000\n",
      "Epoch 286/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2516 - accuracy: 0.9219 - val_loss: 0.5495 - val_accuracy: 0.7000\n",
      "Epoch 287/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2398 - accuracy: 0.9427 - val_loss: 0.5489 - val_accuracy: 0.7000\n",
      "Epoch 288/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2180 - accuracy: 0.9583 - val_loss: 0.5491 - val_accuracy: 0.7000\n",
      "Epoch 289/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2428 - accuracy: 0.9167 - val_loss: 0.5492 - val_accuracy: 0.7000\n",
      "Epoch 290/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2398 - accuracy: 0.9375 - val_loss: 0.5490 - val_accuracy: 0.7500\n",
      "Epoch 291/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2359 - accuracy: 0.9531 - val_loss: 0.5492 - val_accuracy: 0.7000\n",
      "Epoch 292/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2465 - accuracy: 0.9323 - val_loss: 0.5488 - val_accuracy: 0.7500\n",
      "Epoch 293/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2572 - accuracy: 0.9323 - val_loss: 0.5486 - val_accuracy: 0.7500\n",
      "Epoch 294/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2548 - accuracy: 0.9219 - val_loss: 0.5491 - val_accuracy: 0.7000\n",
      "Epoch 295/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2417 - accuracy: 0.9531 - val_loss: 0.5489 - val_accuracy: 0.7500\n",
      "Epoch 296/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2470 - accuracy: 0.9115 - val_loss: 0.5486 - val_accuracy: 0.7500\n",
      "Epoch 297/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2692 - accuracy: 0.9115 - val_loss: 0.5486 - val_accuracy: 0.7500\n",
      "Epoch 298/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2448 - accuracy: 0.9375 - val_loss: 0.5487 - val_accuracy: 0.7500\n",
      "Epoch 299/30900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.2554 - accuracy: 0.9167 - val_loss: 0.5489 - val_accuracy: 0.7000\n",
      "Epoch 300/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2347 - accuracy: 0.9375 - val_loss: 0.5490 - val_accuracy: 0.7500\n",
      "Epoch 301/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2690 - accuracy: 0.9167 - val_loss: 0.5491 - val_accuracy: 0.7500\n",
      "Epoch 302/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2302 - accuracy: 0.9531 - val_loss: 0.5495 - val_accuracy: 0.7500\n",
      "Epoch 303/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2434 - accuracy: 0.9479 - val_loss: 0.5501 - val_accuracy: 0.7500\n",
      "Epoch 304/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2970 - accuracy: 0.8958 - val_loss: 0.5502 - val_accuracy: 0.7500\n",
      "Epoch 305/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2376 - accuracy: 0.9427 - val_loss: 0.5505 - val_accuracy: 0.7500\n",
      "Epoch 306/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2623 - accuracy: 0.9323 - val_loss: 0.5505 - val_accuracy: 0.7500\n",
      "Epoch 307/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2608 - accuracy: 0.9271 - val_loss: 0.5502 - val_accuracy: 0.7500\n",
      "Epoch 308/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2321 - accuracy: 0.9479 - val_loss: 0.5499 - val_accuracy: 0.8000\n",
      "Epoch 309/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2892 - accuracy: 0.9271 - val_loss: 0.5498 - val_accuracy: 0.8000\n",
      "Epoch 310/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2598 - accuracy: 0.9271 - val_loss: 0.5498 - val_accuracy: 0.7500\n",
      "Epoch 311/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2406 - accuracy: 0.9219 - val_loss: 0.5500 - val_accuracy: 0.7500\n",
      "Epoch 312/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2599 - accuracy: 0.9167 - val_loss: 0.5500 - val_accuracy: 0.7500\n",
      "Epoch 313/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2264 - accuracy: 0.9479 - val_loss: 0.5502 - val_accuracy: 0.7500\n",
      "Epoch 314/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2420 - accuracy: 0.9115 - val_loss: 0.5503 - val_accuracy: 0.7500\n",
      "Epoch 315/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2207 - accuracy: 0.9583 - val_loss: 0.5499 - val_accuracy: 0.7500\n",
      "Epoch 316/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2482 - accuracy: 0.9427 - val_loss: 0.5499 - val_accuracy: 0.7500\n",
      "Epoch 317/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2521 - accuracy: 0.9427 - val_loss: 0.5497 - val_accuracy: 0.7500\n",
      "Epoch 318/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2270 - accuracy: 0.9375 - val_loss: 0.5500 - val_accuracy: 0.7500\n",
      "Epoch 319/30900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.2510 - accuracy: 0.9583 - val_loss: 0.5493 - val_accuracy: 0.7500\n",
      "Epoch 320/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2414 - accuracy: 0.9375 - val_loss: 0.5489 - val_accuracy: 0.7500\n",
      "Epoch 321/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2524 - accuracy: 0.9271 - val_loss: 0.5491 - val_accuracy: 0.7500\n",
      "Epoch 322/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2326 - accuracy: 0.9271 - val_loss: 0.5494 - val_accuracy: 0.7500\n",
      "Epoch 323/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2507 - accuracy: 0.9271 - val_loss: 0.5495 - val_accuracy: 0.7500\n",
      "Epoch 324/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2173 - accuracy: 0.9427 - val_loss: 0.5494 - val_accuracy: 0.7500\n",
      "Epoch 325/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2162 - accuracy: 0.9688 - val_loss: 0.5496 - val_accuracy: 0.7500\n",
      "Epoch 326/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2522 - accuracy: 0.9219 - val_loss: 0.5494 - val_accuracy: 0.7500\n",
      "Epoch 327/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2145 - accuracy: 0.9583 - val_loss: 0.5497 - val_accuracy: 0.7500\n",
      "Epoch 328/30900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.2584 - accuracy: 0.9115 - val_loss: 0.5501 - val_accuracy: 0.7500\n",
      "Epoch 329/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2184 - accuracy: 0.9531 - val_loss: 0.5501 - val_accuracy: 0.7500\n",
      "Epoch 330/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2220 - accuracy: 0.9375 - val_loss: 0.5498 - val_accuracy: 0.7500\n",
      "Epoch 331/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2335 - accuracy: 0.9271 - val_loss: 0.5499 - val_accuracy: 0.7500\n",
      "Epoch 332/30900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2218 - accuracy: 0.9323 - val_loss: 0.5499 - val_accuracy: 0.7500\n",
      "Epoch 333/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1997 - accuracy: 0.9792 - val_loss: 0.5501 - val_accuracy: 0.7500\n",
      "Epoch 334/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1975 - accuracy: 0.9635 - val_loss: 0.5502 - val_accuracy: 0.7500\n",
      "Epoch 335/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2264 - accuracy: 0.9427 - val_loss: 0.5506 - val_accuracy: 0.7500\n",
      "Epoch 336/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2420 - accuracy: 0.9167 - val_loss: 0.5508 - val_accuracy: 0.7500\n",
      "Epoch 337/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2325 - accuracy: 0.9167 - val_loss: 0.5509 - val_accuracy: 0.7500\n",
      "Epoch 338/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2533 - accuracy: 0.9167 - val_loss: 0.5509 - val_accuracy: 0.7500\n",
      "Epoch 339/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2329 - accuracy: 0.9271 - val_loss: 0.5514 - val_accuracy: 0.8000\n",
      "Epoch 340/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1843 - accuracy: 0.9531 - val_loss: 0.5515 - val_accuracy: 0.8000\n",
      "Epoch 341/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2417 - accuracy: 0.9323 - val_loss: 0.5515 - val_accuracy: 0.8000\n",
      "Epoch 342/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2229 - accuracy: 0.9583 - val_loss: 0.5519 - val_accuracy: 0.8000\n",
      "Epoch 343/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2428 - accuracy: 0.9271 - val_loss: 0.5524 - val_accuracy: 0.8000\n",
      "Epoch 344/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1972 - accuracy: 0.9531 - val_loss: 0.5528 - val_accuracy: 0.8000\n",
      "Epoch 345/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2149 - accuracy: 0.9427 - val_loss: 0.5530 - val_accuracy: 0.8000\n",
      "Epoch 346/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2201 - accuracy: 0.9323 - val_loss: 0.5531 - val_accuracy: 0.8000\n",
      "Epoch 347/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2020 - accuracy: 0.9375 - val_loss: 0.5529 - val_accuracy: 0.8000\n",
      "Epoch 348/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2788 - accuracy: 0.9062 - val_loss: 0.5528 - val_accuracy: 0.8000\n",
      "Epoch 349/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2167 - accuracy: 0.9635 - val_loss: 0.5528 - val_accuracy: 0.8000\n",
      "Epoch 350/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1885 - accuracy: 0.9531 - val_loss: 0.5527 - val_accuracy: 0.8000\n",
      "Epoch 351/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2027 - accuracy: 0.9479 - val_loss: 0.5526 - val_accuracy: 0.8000\n",
      "Epoch 352/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2534 - accuracy: 0.9062 - val_loss: 0.5531 - val_accuracy: 0.8000\n",
      "Epoch 353/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2305 - accuracy: 0.9531 - val_loss: 0.5532 - val_accuracy: 0.8000\n",
      "Epoch 354/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2151 - accuracy: 0.9479 - val_loss: 0.5537 - val_accuracy: 0.8000\n",
      "Epoch 355/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2088 - accuracy: 0.9375 - val_loss: 0.5540 - val_accuracy: 0.8000\n",
      "Epoch 356/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2383 - accuracy: 0.9167 - val_loss: 0.5545 - val_accuracy: 0.8000\n",
      "Epoch 357/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1968 - accuracy: 0.9531 - val_loss: 0.5545 - val_accuracy: 0.8000\n",
      "Epoch 358/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2128 - accuracy: 0.9479 - val_loss: 0.5543 - val_accuracy: 0.8000\n",
      "Epoch 359/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2417 - accuracy: 0.9167 - val_loss: 0.5539 - val_accuracy: 0.8000\n",
      "Epoch 360/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2324 - accuracy: 0.9271 - val_loss: 0.5540 - val_accuracy: 0.8000\n",
      "Epoch 361/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2149 - accuracy: 0.9479 - val_loss: 0.5542 - val_accuracy: 0.8000\n",
      "Epoch 362/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2273 - accuracy: 0.9375 - val_loss: 0.5541 - val_accuracy: 0.8000\n",
      "Epoch 363/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1942 - accuracy: 0.9688 - val_loss: 0.5540 - val_accuracy: 0.8000\n",
      "Epoch 364/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2165 - accuracy: 0.9427 - val_loss: 0.5543 - val_accuracy: 0.8000\n",
      "Epoch 365/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1903 - accuracy: 0.9688 - val_loss: 0.5545 - val_accuracy: 0.8000\n",
      "Epoch 366/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2219 - accuracy: 0.9271 - val_loss: 0.5541 - val_accuracy: 0.8000\n",
      "Epoch 367/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2003 - accuracy: 0.9375 - val_loss: 0.5543 - val_accuracy: 0.8000\n",
      "Epoch 368/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2259 - accuracy: 0.9375 - val_loss: 0.5544 - val_accuracy: 0.8000\n",
      "Epoch 369/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2253 - accuracy: 0.9271 - val_loss: 0.5546 - val_accuracy: 0.8000\n",
      "Epoch 370/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2036 - accuracy: 0.9688 - val_loss: 0.5551 - val_accuracy: 0.8000\n",
      "Epoch 371/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2155 - accuracy: 0.9479 - val_loss: 0.5557 - val_accuracy: 0.8000\n",
      "Epoch 372/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2038 - accuracy: 0.9635 - val_loss: 0.5554 - val_accuracy: 0.8000\n",
      "Epoch 373/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1823 - accuracy: 0.9740 - val_loss: 0.5551 - val_accuracy: 0.8000\n",
      "Epoch 374/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1881 - accuracy: 0.9531 - val_loss: 0.5551 - val_accuracy: 0.8000\n",
      "Epoch 375/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1964 - accuracy: 0.9635 - val_loss: 0.5547 - val_accuracy: 0.8000\n",
      "Epoch 376/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2216 - accuracy: 0.9323 - val_loss: 0.5546 - val_accuracy: 0.8000\n",
      "Epoch 377/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2097 - accuracy: 0.9583 - val_loss: 0.5542 - val_accuracy: 0.8000\n",
      "Epoch 378/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1836 - accuracy: 0.9635 - val_loss: 0.5540 - val_accuracy: 0.8000\n",
      "Epoch 379/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2441 - accuracy: 0.8906 - val_loss: 0.5540 - val_accuracy: 0.8000\n",
      "Epoch 380/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1876 - accuracy: 0.9740 - val_loss: 0.5540 - val_accuracy: 0.8000\n",
      "Epoch 381/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1815 - accuracy: 0.9740 - val_loss: 0.5538 - val_accuracy: 0.8000\n",
      "Epoch 382/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2293 - accuracy: 0.9375 - val_loss: 0.5539 - val_accuracy: 0.8000\n",
      "Epoch 383/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2069 - accuracy: 0.9427 - val_loss: 0.5538 - val_accuracy: 0.8000\n",
      "Epoch 384/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2053 - accuracy: 0.9323 - val_loss: 0.5541 - val_accuracy: 0.8000\n",
      "Epoch 385/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2158 - accuracy: 0.9479 - val_loss: 0.5540 - val_accuracy: 0.8000\n",
      "Epoch 386/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2210 - accuracy: 0.9479 - val_loss: 0.5541 - val_accuracy: 0.8000\n",
      "Epoch 387/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2145 - accuracy: 0.9219 - val_loss: 0.5536 - val_accuracy: 0.8000\n",
      "Epoch 388/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2229 - accuracy: 0.9427 - val_loss: 0.5542 - val_accuracy: 0.8000\n",
      "Epoch 389/30900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2090 - accuracy: 0.9479 - val_loss: 0.5538 - val_accuracy: 0.8000\n",
      "Epoch 390/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1947 - accuracy: 0.9323 - val_loss: 0.5533 - val_accuracy: 0.8000\n",
      "Epoch 391/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2220 - accuracy: 0.9375 - val_loss: 0.5530 - val_accuracy: 0.8000\n",
      "Epoch 392/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1819 - accuracy: 0.9583 - val_loss: 0.5528 - val_accuracy: 0.8000\n",
      "Epoch 393/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2106 - accuracy: 0.9479 - val_loss: 0.5527 - val_accuracy: 0.8000\n",
      "Epoch 394/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1926 - accuracy: 0.9479 - val_loss: 0.5530 - val_accuracy: 0.8000\n",
      "Epoch 395/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1851 - accuracy: 0.9583 - val_loss: 0.5527 - val_accuracy: 0.8000\n",
      "Epoch 396/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2165 - accuracy: 0.9323 - val_loss: 0.5528 - val_accuracy: 0.8000\n",
      "Epoch 397/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1862 - accuracy: 0.9583 - val_loss: 0.5533 - val_accuracy: 0.8000\n",
      "Epoch 398/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1947 - accuracy: 0.9375 - val_loss: 0.5534 - val_accuracy: 0.8000\n",
      "Epoch 399/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2321 - accuracy: 0.9375 - val_loss: 0.5537 - val_accuracy: 0.8000\n",
      "Epoch 400/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1821 - accuracy: 0.9688 - val_loss: 0.5541 - val_accuracy: 0.8000\n",
      "Epoch 401/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1894 - accuracy: 0.9479 - val_loss: 0.5541 - val_accuracy: 0.8000\n",
      "Epoch 402/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2164 - accuracy: 0.9531 - val_loss: 0.5543 - val_accuracy: 0.8000\n",
      "Epoch 403/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2021 - accuracy: 0.9479 - val_loss: 0.5543 - val_accuracy: 0.8000\n",
      "Epoch 404/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2334 - accuracy: 0.9375 - val_loss: 0.5541 - val_accuracy: 0.8000\n",
      "Epoch 405/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1790 - accuracy: 0.9740 - val_loss: 0.5541 - val_accuracy: 0.8000\n",
      "Epoch 406/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1749 - accuracy: 0.9792 - val_loss: 0.5541 - val_accuracy: 0.8000\n",
      "Epoch 407/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1715 - accuracy: 0.9740 - val_loss: 0.5544 - val_accuracy: 0.8000\n",
      "Epoch 408/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1820 - accuracy: 0.9688 - val_loss: 0.5550 - val_accuracy: 0.8000\n",
      "Epoch 409/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1939 - accuracy: 0.9375 - val_loss: 0.5550 - val_accuracy: 0.8000\n",
      "Epoch 410/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1894 - accuracy: 0.9427 - val_loss: 0.5550 - val_accuracy: 0.8000\n",
      "Epoch 411/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1815 - accuracy: 0.9635 - val_loss: 0.5547 - val_accuracy: 0.8000\n",
      "Epoch 412/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2073 - accuracy: 0.9479 - val_loss: 0.5554 - val_accuracy: 0.8000\n",
      "Epoch 413/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2033 - accuracy: 0.9531 - val_loss: 0.5556 - val_accuracy: 0.8000\n",
      "Epoch 414/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1947 - accuracy: 0.9479 - val_loss: 0.5558 - val_accuracy: 0.8000\n",
      "Epoch 415/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1915 - accuracy: 0.9583 - val_loss: 0.5555 - val_accuracy: 0.8000\n",
      "Epoch 416/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1853 - accuracy: 0.9583 - val_loss: 0.5554 - val_accuracy: 0.8000\n",
      "Epoch 417/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1910 - accuracy: 0.9427 - val_loss: 0.5552 - val_accuracy: 0.8000\n",
      "Epoch 418/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2109 - accuracy: 0.9479 - val_loss: 0.5554 - val_accuracy: 0.8000\n",
      "Epoch 419/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2107 - accuracy: 0.9427 - val_loss: 0.5555 - val_accuracy: 0.8000\n",
      "Epoch 420/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1981 - accuracy: 0.9479 - val_loss: 0.5556 - val_accuracy: 0.8000\n",
      "Epoch 421/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1883 - accuracy: 0.9583 - val_loss: 0.5555 - val_accuracy: 0.8000\n",
      "Epoch 422/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1703 - accuracy: 0.9740 - val_loss: 0.5554 - val_accuracy: 0.8000\n",
      "Epoch 423/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1823 - accuracy: 0.9531 - val_loss: 0.5556 - val_accuracy: 0.8000\n",
      "Epoch 424/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1971 - accuracy: 0.9531 - val_loss: 0.5554 - val_accuracy: 0.8000\n",
      "Epoch 425/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1895 - accuracy: 0.9635 - val_loss: 0.5555 - val_accuracy: 0.8000\n",
      "Epoch 426/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1811 - accuracy: 0.9635 - val_loss: 0.5558 - val_accuracy: 0.8000\n",
      "Epoch 427/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1985 - accuracy: 0.9479 - val_loss: 0.5558 - val_accuracy: 0.8000\n",
      "Epoch 428/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1784 - accuracy: 0.9688 - val_loss: 0.5559 - val_accuracy: 0.8000\n",
      "Epoch 429/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1940 - accuracy: 0.9531 - val_loss: 0.5560 - val_accuracy: 0.8000\n",
      "Epoch 430/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1761 - accuracy: 0.9740 - val_loss: 0.5561 - val_accuracy: 0.8000\n",
      "Epoch 431/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1783 - accuracy: 0.9635 - val_loss: 0.5561 - val_accuracy: 0.8000\n",
      "Epoch 432/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2006 - accuracy: 0.9583 - val_loss: 0.5560 - val_accuracy: 0.8000\n",
      "Epoch 433/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1774 - accuracy: 0.9583 - val_loss: 0.5561 - val_accuracy: 0.8000\n",
      "Epoch 434/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1568 - accuracy: 0.9583 - val_loss: 0.5565 - val_accuracy: 0.8000\n",
      "Epoch 435/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1995 - accuracy: 0.9323 - val_loss: 0.5566 - val_accuracy: 0.8000\n",
      "Epoch 436/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1850 - accuracy: 0.9635 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 437/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1990 - accuracy: 0.9635 - val_loss: 0.5581 - val_accuracy: 0.8000\n",
      "Epoch 438/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1748 - accuracy: 0.9688 - val_loss: 0.5585 - val_accuracy: 0.8000\n",
      "Epoch 439/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1913 - accuracy: 0.9583 - val_loss: 0.5583 - val_accuracy: 0.8000\n",
      "Epoch 440/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1856 - accuracy: 0.9583 - val_loss: 0.5588 - val_accuracy: 0.8000\n",
      "Epoch 441/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1747 - accuracy: 0.9740 - val_loss: 0.5592 - val_accuracy: 0.8000\n",
      "Epoch 442/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1658 - accuracy: 0.9688 - val_loss: 0.5591 - val_accuracy: 0.8000\n",
      "Epoch 443/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1553 - accuracy: 0.9792 - val_loss: 0.5590 - val_accuracy: 0.8000\n",
      "Epoch 444/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1618 - accuracy: 0.9635 - val_loss: 0.5586 - val_accuracy: 0.8000\n",
      "Epoch 445/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1646 - accuracy: 0.9583 - val_loss: 0.5582 - val_accuracy: 0.8000\n",
      "Epoch 446/30900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1514 - accuracy: 0.9844 - val_loss: 0.5586 - val_accuracy: 0.8000\n",
      "Epoch 447/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1740 - accuracy: 0.9479 - val_loss: 0.5590 - val_accuracy: 0.8000\n",
      "Epoch 448/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1814 - accuracy: 0.9688 - val_loss: 0.5596 - val_accuracy: 0.8000\n",
      "Epoch 449/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1657 - accuracy: 0.9583 - val_loss: 0.5599 - val_accuracy: 0.8000\n",
      "Epoch 450/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1880 - accuracy: 0.9427 - val_loss: 0.5598 - val_accuracy: 0.8000\n",
      "Epoch 451/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1787 - accuracy: 0.9375 - val_loss: 0.5599 - val_accuracy: 0.8000\n",
      "Epoch 452/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1742 - accuracy: 0.9583 - val_loss: 0.5600 - val_accuracy: 0.8000\n",
      "Epoch 453/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1856 - accuracy: 0.9531 - val_loss: 0.5603 - val_accuracy: 0.8000\n",
      "Epoch 454/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2054 - accuracy: 0.9531 - val_loss: 0.5606 - val_accuracy: 0.8000\n",
      "Epoch 455/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1913 - accuracy: 0.9323 - val_loss: 0.5607 - val_accuracy: 0.8000\n",
      "Epoch 456/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2231 - accuracy: 0.9271 - val_loss: 0.5612 - val_accuracy: 0.8000\n",
      "Epoch 457/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1702 - accuracy: 0.9531 - val_loss: 0.5611 - val_accuracy: 0.8000\n",
      "Epoch 458/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1665 - accuracy: 0.9635 - val_loss: 0.5614 - val_accuracy: 0.8000\n",
      "Epoch 459/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1542 - accuracy: 0.9792 - val_loss: 0.5616 - val_accuracy: 0.8000\n",
      "Epoch 460/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1653 - accuracy: 0.9479 - val_loss: 0.5618 - val_accuracy: 0.8000\n",
      "Epoch 461/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1459 - accuracy: 0.9792 - val_loss: 0.5618 - val_accuracy: 0.8000\n",
      "Epoch 462/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1710 - accuracy: 0.9583 - val_loss: 0.5617 - val_accuracy: 0.8000\n",
      "Epoch 463/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2069 - accuracy: 0.9479 - val_loss: 0.5618 - val_accuracy: 0.8000\n",
      "Epoch 464/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1668 - accuracy: 0.9688 - val_loss: 0.5620 - val_accuracy: 0.8000\n",
      "Epoch 465/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1554 - accuracy: 0.9635 - val_loss: 0.5624 - val_accuracy: 0.8000\n",
      "Epoch 466/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1903 - accuracy: 0.9583 - val_loss: 0.5621 - val_accuracy: 0.8000\n",
      "Epoch 467/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1534 - accuracy: 0.9688 - val_loss: 0.5622 - val_accuracy: 0.8000\n",
      "Epoch 468/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1878 - accuracy: 0.9323 - val_loss: 0.5621 - val_accuracy: 0.8000\n",
      "Epoch 469/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1767 - accuracy: 0.9375 - val_loss: 0.5618 - val_accuracy: 0.8000\n",
      "Epoch 470/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1467 - accuracy: 0.9792 - val_loss: 0.5614 - val_accuracy: 0.8000\n",
      "Epoch 471/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1922 - accuracy: 0.9583 - val_loss: 0.5609 - val_accuracy: 0.8000\n",
      "Epoch 472/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1768 - accuracy: 0.9427 - val_loss: 0.5606 - val_accuracy: 0.8000\n",
      "Epoch 473/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1705 - accuracy: 0.9531 - val_loss: 0.5609 - val_accuracy: 0.8000\n",
      "Epoch 474/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1657 - accuracy: 0.9479 - val_loss: 0.5613 - val_accuracy: 0.8000\n",
      "Epoch 475/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1557 - accuracy: 0.9740 - val_loss: 0.5616 - val_accuracy: 0.8000\n",
      "Epoch 476/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1634 - accuracy: 0.9688 - val_loss: 0.5620 - val_accuracy: 0.8000\n",
      "Epoch 477/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1825 - accuracy: 0.9375 - val_loss: 0.5628 - val_accuracy: 0.8000\n",
      "Epoch 478/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1797 - accuracy: 0.9479 - val_loss: 0.5633 - val_accuracy: 0.8000\n",
      "Epoch 479/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1934 - accuracy: 0.9323 - val_loss: 0.5638 - val_accuracy: 0.8000\n",
      "Epoch 480/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1639 - accuracy: 0.9583 - val_loss: 0.5644 - val_accuracy: 0.8000\n",
      "Epoch 481/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1584 - accuracy: 0.9635 - val_loss: 0.5641 - val_accuracy: 0.8000\n",
      "Epoch 482/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1652 - accuracy: 0.9531 - val_loss: 0.5639 - val_accuracy: 0.8000\n",
      "Epoch 483/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1425 - accuracy: 0.9740 - val_loss: 0.5640 - val_accuracy: 0.8000\n",
      "Epoch 484/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1492 - accuracy: 0.9635 - val_loss: 0.5637 - val_accuracy: 0.8000\n",
      "Epoch 485/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1800 - accuracy: 0.9375 - val_loss: 0.5639 - val_accuracy: 0.8000\n",
      "Epoch 486/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2037 - accuracy: 0.9323 - val_loss: 0.5644 - val_accuracy: 0.8000\n",
      "Epoch 487/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1697 - accuracy: 0.9688 - val_loss: 0.5642 - val_accuracy: 0.8000\n",
      "Epoch 488/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1701 - accuracy: 0.9583 - val_loss: 0.5645 - val_accuracy: 0.8000\n",
      "Epoch 489/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1720 - accuracy: 0.9531 - val_loss: 0.5647 - val_accuracy: 0.8000\n",
      "Epoch 490/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1843 - accuracy: 0.9583 - val_loss: 0.5650 - val_accuracy: 0.8000\n",
      "Epoch 491/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1658 - accuracy: 0.9479 - val_loss: 0.5649 - val_accuracy: 0.8000\n",
      "Epoch 492/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1603 - accuracy: 0.9688 - val_loss: 0.5653 - val_accuracy: 0.8000\n",
      "Epoch 493/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1638 - accuracy: 0.9635 - val_loss: 0.5654 - val_accuracy: 0.8000\n",
      "Epoch 494/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1935 - accuracy: 0.9375 - val_loss: 0.5654 - val_accuracy: 0.8000\n",
      "Epoch 495/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1617 - accuracy: 0.9583 - val_loss: 0.5655 - val_accuracy: 0.8000\n",
      "Epoch 496/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1412 - accuracy: 0.9792 - val_loss: 0.5661 - val_accuracy: 0.8000\n",
      "Epoch 497/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1733 - accuracy: 0.9688 - val_loss: 0.5666 - val_accuracy: 0.8000\n",
      "Epoch 498/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1690 - accuracy: 0.9688 - val_loss: 0.5668 - val_accuracy: 0.8000\n",
      "Epoch 499/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1485 - accuracy: 0.9792 - val_loss: 0.5672 - val_accuracy: 0.8000\n",
      "Epoch 500/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1482 - accuracy: 0.9635 - val_loss: 0.5670 - val_accuracy: 0.8000\n",
      "Epoch 501/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1253 - accuracy: 0.9844 - val_loss: 0.5663 - val_accuracy: 0.8000\n",
      "Epoch 502/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1399 - accuracy: 0.9844 - val_loss: 0.5659 - val_accuracy: 0.8000\n",
      "Epoch 503/30900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1408 - accuracy: 0.9740 - val_loss: 0.5657 - val_accuracy: 0.8000\n",
      "Epoch 504/30900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1390 - accuracy: 0.9792 - val_loss: 0.5658 - val_accuracy: 0.8000\n",
      "Epoch 505/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1497 - accuracy: 0.9635 - val_loss: 0.5658 - val_accuracy: 0.8000\n",
      "Epoch 506/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1371 - accuracy: 0.9896 - val_loss: 0.5655 - val_accuracy: 0.8000\n",
      "Epoch 507/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1432 - accuracy: 0.9635 - val_loss: 0.5655 - val_accuracy: 0.8000\n",
      "Epoch 508/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1630 - accuracy: 0.9635 - val_loss: 0.5653 - val_accuracy: 0.8000\n",
      "Epoch 509/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1542 - accuracy: 0.9740 - val_loss: 0.5659 - val_accuracy: 0.8000\n",
      "Epoch 510/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1594 - accuracy: 0.9792 - val_loss: 0.5666 - val_accuracy: 0.8000\n",
      "Epoch 511/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1465 - accuracy: 0.9583 - val_loss: 0.5667 - val_accuracy: 0.8000\n",
      "Epoch 512/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1797 - accuracy: 0.9375 - val_loss: 0.5665 - val_accuracy: 0.8000\n",
      "Epoch 513/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1649 - accuracy: 0.9635 - val_loss: 0.5669 - val_accuracy: 0.8000\n",
      "Epoch 514/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1859 - accuracy: 0.9427 - val_loss: 0.5679 - val_accuracy: 0.8000\n",
      "Epoch 515/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1672 - accuracy: 0.9635 - val_loss: 0.5677 - val_accuracy: 0.8000\n",
      "Epoch 516/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1529 - accuracy: 0.9844 - val_loss: 0.5678 - val_accuracy: 0.8000\n",
      "Epoch 517/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1478 - accuracy: 0.9531 - val_loss: 0.5679 - val_accuracy: 0.8000\n",
      "Epoch 518/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2017 - accuracy: 0.9323 - val_loss: 0.5674 - val_accuracy: 0.8000\n",
      "Epoch 519/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1752 - accuracy: 0.9531 - val_loss: 0.5669 - val_accuracy: 0.8000\n",
      "Epoch 520/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1685 - accuracy: 0.9583 - val_loss: 0.5671 - val_accuracy: 0.8000\n",
      "Epoch 521/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1444 - accuracy: 0.9896 - val_loss: 0.5669 - val_accuracy: 0.8000\n",
      "Epoch 522/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1794 - accuracy: 0.9479 - val_loss: 0.5673 - val_accuracy: 0.8000\n",
      "Epoch 523/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1442 - accuracy: 0.9635 - val_loss: 0.5669 - val_accuracy: 0.8000\n",
      "Epoch 524/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1778 - accuracy: 0.9427 - val_loss: 0.5672 - val_accuracy: 0.8000\n",
      "Epoch 525/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1348 - accuracy: 0.9844 - val_loss: 0.5674 - val_accuracy: 0.8000\n",
      "Epoch 526/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1389 - accuracy: 0.9896 - val_loss: 0.5674 - val_accuracy: 0.8000\n",
      "Epoch 527/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1554 - accuracy: 0.9635 - val_loss: 0.5671 - val_accuracy: 0.8000\n",
      "Epoch 528/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1650 - accuracy: 0.9479 - val_loss: 0.5677 - val_accuracy: 0.8000\n",
      "Epoch 529/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1665 - accuracy: 0.9688 - val_loss: 0.5679 - val_accuracy: 0.8000\n",
      "Epoch 530/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1470 - accuracy: 0.9740 - val_loss: 0.5679 - val_accuracy: 0.8000\n",
      "Epoch 531/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1814 - accuracy: 0.9375 - val_loss: 0.5679 - val_accuracy: 0.8000\n",
      "Epoch 532/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2212 - accuracy: 0.9219 - val_loss: 0.5680 - val_accuracy: 0.8000\n",
      "Epoch 533/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1461 - accuracy: 0.9635 - val_loss: 0.5686 - val_accuracy: 0.8000\n",
      "Epoch 534/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1512 - accuracy: 0.9635 - val_loss: 0.5688 - val_accuracy: 0.8000\n",
      "Epoch 535/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1747 - accuracy: 0.9583 - val_loss: 0.5688 - val_accuracy: 0.8000\n",
      "Epoch 536/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1425 - accuracy: 0.9740 - val_loss: 0.5691 - val_accuracy: 0.8000\n",
      "Epoch 537/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1415 - accuracy: 0.9896 - val_loss: 0.5690 - val_accuracy: 0.8000\n",
      "Epoch 538/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1476 - accuracy: 0.9740 - val_loss: 0.5690 - val_accuracy: 0.8000\n",
      "Epoch 539/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1273 - accuracy: 0.9792 - val_loss: 0.5692 - val_accuracy: 0.8000\n",
      "Epoch 540/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1539 - accuracy: 0.9635 - val_loss: 0.5693 - val_accuracy: 0.8000\n",
      "Epoch 541/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1461 - accuracy: 0.9583 - val_loss: 0.5691 - val_accuracy: 0.8000\n",
      "Epoch 542/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1541 - accuracy: 0.9740 - val_loss: 0.5686 - val_accuracy: 0.8000\n",
      "Epoch 543/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1223 - accuracy: 0.9740 - val_loss: 0.5685 - val_accuracy: 0.8000\n",
      "Epoch 544/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1384 - accuracy: 0.9688 - val_loss: 0.5684 - val_accuracy: 0.8000\n",
      "Epoch 545/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1332 - accuracy: 0.9740 - val_loss: 0.5690 - val_accuracy: 0.8000\n",
      "Epoch 546/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1772 - accuracy: 0.9531 - val_loss: 0.5695 - val_accuracy: 0.8000\n",
      "Epoch 547/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1622 - accuracy: 0.9479 - val_loss: 0.5694 - val_accuracy: 0.8000\n",
      "Epoch 548/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1596 - accuracy: 0.9531 - val_loss: 0.5702 - val_accuracy: 0.8000\n",
      "Epoch 549/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1736 - accuracy: 0.9635 - val_loss: 0.5702 - val_accuracy: 0.8000\n",
      "Epoch 550/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1687 - accuracy: 0.9479 - val_loss: 0.5701 - val_accuracy: 0.8000\n",
      "Epoch 551/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1554 - accuracy: 0.9583 - val_loss: 0.5697 - val_accuracy: 0.8000\n",
      "Epoch 552/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1241 - accuracy: 0.9740 - val_loss: 0.5694 - val_accuracy: 0.8000\n",
      "Epoch 553/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1372 - accuracy: 0.9844 - val_loss: 0.5697 - val_accuracy: 0.8000\n",
      "Epoch 554/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1421 - accuracy: 0.9740 - val_loss: 0.5694 - val_accuracy: 0.8000\n",
      "Epoch 555/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1500 - accuracy: 0.9531 - val_loss: 0.5694 - val_accuracy: 0.8000\n",
      "Epoch 556/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1653 - accuracy: 0.9688 - val_loss: 0.5696 - val_accuracy: 0.8000\n",
      "Epoch 557/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1314 - accuracy: 0.9740 - val_loss: 0.5701 - val_accuracy: 0.8000\n",
      "Epoch 558/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1437 - accuracy: 0.9740 - val_loss: 0.5702 - val_accuracy: 0.8000\n",
      "Epoch 559/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1194 - accuracy: 0.9792 - val_loss: 0.5702 - val_accuracy: 0.8000\n",
      "Epoch 560/30900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1386 - accuracy: 0.9740 - val_loss: 0.5706 - val_accuracy: 0.8000\n",
      "Epoch 561/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1566 - accuracy: 0.9479 - val_loss: 0.5709 - val_accuracy: 0.8000\n",
      "Epoch 562/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1275 - accuracy: 0.9688 - val_loss: 0.5707 - val_accuracy: 0.8000\n",
      "Epoch 563/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1236 - accuracy: 0.9740 - val_loss: 0.5710 - val_accuracy: 0.8000\n",
      "Epoch 564/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1571 - accuracy: 0.9583 - val_loss: 0.5711 - val_accuracy: 0.8000\n",
      "Epoch 565/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1375 - accuracy: 0.9688 - val_loss: 0.5713 - val_accuracy: 0.8000\n",
      "Epoch 566/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1259 - accuracy: 0.9792 - val_loss: 0.5716 - val_accuracy: 0.8000\n",
      "Epoch 567/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1419 - accuracy: 0.9688 - val_loss: 0.5719 - val_accuracy: 0.8000\n",
      "Epoch 568/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1271 - accuracy: 0.9688 - val_loss: 0.5717 - val_accuracy: 0.8000\n",
      "Epoch 569/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1678 - accuracy: 0.9531 - val_loss: 0.5712 - val_accuracy: 0.8000\n",
      "Epoch 570/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1641 - accuracy: 0.9583 - val_loss: 0.5708 - val_accuracy: 0.8000\n",
      "Epoch 571/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1365 - accuracy: 0.9688 - val_loss: 0.5708 - val_accuracy: 0.8000\n",
      "Epoch 572/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1459 - accuracy: 0.9531 - val_loss: 0.5710 - val_accuracy: 0.8000\n",
      "Epoch 573/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1532 - accuracy: 0.9688 - val_loss: 0.5709 - val_accuracy: 0.8000\n",
      "Epoch 574/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1547 - accuracy: 0.9531 - val_loss: 0.5708 - val_accuracy: 0.8000\n",
      "Epoch 575/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1557 - accuracy: 0.9531 - val_loss: 0.5713 - val_accuracy: 0.8000\n",
      "Epoch 576/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1322 - accuracy: 0.9792 - val_loss: 0.5720 - val_accuracy: 0.8000\n",
      "Epoch 577/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1444 - accuracy: 0.9688 - val_loss: 0.5729 - val_accuracy: 0.8000\n",
      "Epoch 578/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1291 - accuracy: 0.9688 - val_loss: 0.5732 - val_accuracy: 0.8000\n",
      "Epoch 579/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1297 - accuracy: 0.9635 - val_loss: 0.5737 - val_accuracy: 0.8000\n",
      "Epoch 580/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1373 - accuracy: 0.9635 - val_loss: 0.5746 - val_accuracy: 0.8000\n",
      "Epoch 581/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1361 - accuracy: 0.9740 - val_loss: 0.5752 - val_accuracy: 0.8000\n",
      "Epoch 582/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1407 - accuracy: 0.9688 - val_loss: 0.5750 - val_accuracy: 0.8000\n",
      "Epoch 583/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1252 - accuracy: 0.9688 - val_loss: 0.5750 - val_accuracy: 0.8000\n",
      "Epoch 584/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1726 - accuracy: 0.9427 - val_loss: 0.5748 - val_accuracy: 0.8000\n",
      "Epoch 585/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1142 - accuracy: 0.9896 - val_loss: 0.5753 - val_accuracy: 0.8000\n",
      "Epoch 586/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1241 - accuracy: 0.9792 - val_loss: 0.5757 - val_accuracy: 0.8000\n",
      "Epoch 587/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1639 - accuracy: 0.9427 - val_loss: 0.5757 - val_accuracy: 0.8000\n",
      "Epoch 588/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1433 - accuracy: 0.9688 - val_loss: 0.5755 - val_accuracy: 0.8000\n",
      "Epoch 589/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1437 - accuracy: 0.9427 - val_loss: 0.5750 - val_accuracy: 0.8000\n",
      "Epoch 590/30900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1576 - accuracy: 0.9635 - val_loss: 0.5753 - val_accuracy: 0.8000\n",
      "Epoch 591/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1480 - accuracy: 0.9635 - val_loss: 0.5754 - val_accuracy: 0.8000\n",
      "Epoch 592/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1797 - accuracy: 0.9479 - val_loss: 0.5742 - val_accuracy: 0.8000\n",
      "Epoch 593/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1589 - accuracy: 0.9479 - val_loss: 0.5743 - val_accuracy: 0.8000\n",
      "Epoch 594/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1409 - accuracy: 0.9844 - val_loss: 0.5746 - val_accuracy: 0.8000\n",
      "Epoch 595/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1308 - accuracy: 0.9583 - val_loss: 0.5744 - val_accuracy: 0.8000\n",
      "Epoch 596/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1464 - accuracy: 0.9635 - val_loss: 0.5747 - val_accuracy: 0.8000\n",
      "Epoch 597/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1421 - accuracy: 0.9635 - val_loss: 0.5751 - val_accuracy: 0.8000\n",
      "Epoch 598/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1503 - accuracy: 0.9635 - val_loss: 0.5752 - val_accuracy: 0.8000\n",
      "Epoch 599/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1284 - accuracy: 0.9740 - val_loss: 0.5753 - val_accuracy: 0.8000\n",
      "Epoch 600/30900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1249 - accuracy: 0.9635 - val_loss: 0.5754 - val_accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(79)\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0000004, beta_1=0.8,beta_2=0.999)\n",
    "model=keras.models.Sequential([keras.layers.Flatten(input_shape=[input_shape,1]),\n",
    "                               keras.layers.BatchNormalization(),\n",
    "                               keras.layers.Dropout(rate=0.2),\n",
    "                               keras.layers.Dense(6000,activation='elu'\n",
    "                                                  ,kernel_initializer='glorot_normal'\n",
    "                                                 #,kernel_regularizer=keras.regularizers.l2(0.1)\n",
    "                                                 ),\n",
    "                               #keras.layers.BatchNormalization(),\n",
    "                               keras.layers.Dropout(rate=0.15),\n",
    "                               keras.layers.Dense(1000,activation='elu'\n",
    "                                                  ,kernel_initializer='GlorotNormal'\n",
    "                                               #  ,kernel_regularizer=keras.regularizers.l2(0.02)\n",
    "                                                 ),\n",
    "                               keras.layers.BatchNormalization(),\n",
    "                               keras.layers.Dropout(rate=0.05),\n",
    "                               keras.layers.Dense(32,activation='elu'\n",
    "                                                  ,kernel_initializer='glorot_normal'\n",
    "                                                 #,kernel_regularizer=keras.regularizers.l2(0.1)\n",
    "                                                 ),\n",
    "                               #keras.layers.BatchNormalization(),\n",
    "                               #keras.layers.Dropout(rate=0.21),\n",
    "                               keras.layers.Dense(1,activation='sigmoid')])\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "root_logdir=os.path.join(os.curdir,'my_logs')\n",
    "def get_run_logdir():\n",
    "    run_id=time.strftime('run_%Y_%m_%d-%H_%M_%S')\n",
    "    return os.path.join(root_logdir,run_id)\n",
    "run_logdir=get_run_logdir()\n",
    "tensorboard_cb=keras.callbacks.TensorBoard(run_logdir)\n",
    "early_stopping_cb=keras.callbacks.EarlyStopping(patience=358,restore_best_weights=True)\n",
    "history=model.fit(np.asarray(train_dataset_pca).reshape(train_dataset_pca.shape),\n",
    "np.asarray(train_dataset.loc[:,'label']).reshape(train_dataset.loc[:,'label'].shape),\n",
    "epochs=30900,validation_data=(np.asarray(val_dataset_pca).reshape(val_dataset_pca.shape),np.asarray(val_dataset.loc[:,'label']).reshape(val_dataset.loc[:,'label'].shape)),\n",
    "                 callbacks=[tensorboard_cb,early_stopping_cb])\n",
    "\n",
    "callbacks=[early_stopping_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "\n",
    "plt.gca().set_ylim(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.savefig('results/my_keras_model_ann.png',bbox_inches='tight')\n",
    "model.save('my_keras_model_ann.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Details about the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 182)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 182)               728       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 182)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6000)              1098000   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              6001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                32032     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 7,135,793\n",
      "Trainable params: 7,133,429\n",
      "Non-trainable params: 2,364\n",
      "_________________________________________________________________\n",
      "0 <tensorflow.python.keras.layers.core.Flatten object at 0x0000020ABF47BCD0>\n",
      "   no activation attribute\n",
      "1 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000020ABF486850>\n",
      "   no activation attribute\n",
      "2 <tensorflow.python.keras.layers.core.Dropout object at 0x0000020ABF48C8E0>\n",
      "   no activation attribute\n",
      "3 <tensorflow.python.keras.layers.core.Dense object at 0x0000020AEF0F3D60>\n",
      "     <function elu at 0x0000020ACB01C1F0>\n",
      "4 <tensorflow.python.keras.layers.core.Dropout object at 0x0000020ABF48A340>\n",
      "   no activation attribute\n",
      "5 <tensorflow.python.keras.layers.core.Dense object at 0x0000020AEF10A550>\n",
      "     <function elu at 0x0000020ACB01C1F0>\n",
      "6 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000020AEF10A8E0>\n",
      "   no activation attribute\n",
      "7 <tensorflow.python.keras.layers.core.Dropout object at 0x0000020AEF112D60>\n",
      "   no activation attribute\n",
      "8 <tensorflow.python.keras.layers.core.Dense object at 0x0000020AEF112A60>\n",
      "     <function elu at 0x0000020ACB01C1F0>\n",
      "9 <tensorflow.python.keras.layers.core.Dense object at 0x0000020AEF129550>\n",
      "     <function sigmoid at 0x0000020ACB01CAF0>\n",
      "{'name': 'flatten', 'trainable': True, 'batch_input_shape': (None, 182, 1), 'dtype': 'float32', 'data_format': 'channels_last'}\n",
      "{'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([1]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}\n",
      "{'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.2, 'noise_shape': None, 'seed': None}\n",
      "{'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 6000, 'activation': 'elu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotNormal', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "{'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.15, 'noise_shape': None, 'seed': None}\n",
      "{'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 1000, 'activation': 'elu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotNormal', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "{'name': 'batch_normalization_1', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([1]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}\n",
      "{'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.05, 'noise_shape': None, 'seed': None}\n",
      "{'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 32, 'activation': 'elu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotNormal', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "{'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 1, 'activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'Adam',\n",
       " 'learning_rate': 4e-07,\n",
       " 'decay': 0.0,\n",
       " 'beta_1': 0.8,\n",
       " 'beta_2': 0.999,\n",
       " 'epsilon': 1e-07,\n",
       " 'amsgrad': False}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=keras.models.load_model('my_keras_model_ann.h5') \n",
    "\n",
    "model.summary()\n",
    "\n",
    "for i, layer in enumerate (model.layers):\n",
    "    print (i, layer)\n",
    "    try:\n",
    "        print (\"    \",layer.activation)\n",
    "    except AttributeError:\n",
    "        print('   no activation attribute')\n",
    "#specific info about each layer\n",
    "for i in range(len(model.layers)):\n",
    "    print(model.layers[i].get_config())\n",
    "#info about optimizers\n",
    "model.optimizer.get_config()       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
